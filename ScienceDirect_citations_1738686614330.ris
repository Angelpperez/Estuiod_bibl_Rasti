TY  - JOUR
T1  - The Role of Large Language Models in Transforming Emergency Medicine: Scoping Review
AU  - Preiksaitis, Carl
AU  - Ashenburg, Nicholas
AU  - Bunney, Gabrielle
AU  - Chu, Andrew
AU  - Kabeer, Rana
AU  - Riley, Fran
AU  - Ribeira, Ryan
AU  - Rose, Christian
JO  - JMIR Medical Informatics
VL  - 12
PY  - 2024
DA  - 2024/01/01/
SN  - 2291-9694
DO  - https://doi.org/10.2196/53787
UR  - https://www.sciencedirect.com/science/article/pii/S2291969424000516
KW  - large language model
KW  - LLM
KW  - emergency medicine
KW  - clinical decision support
KW  - workflow efficiency
KW  - medical education
KW  - artificial intelligence
KW  - AI
KW  - natural language processing
KW  - NLP
KW  - AI literacy
KW  - ChatGPT
KW  - Bard
KW  - Pathways Language Model
KW  - Med-PaLM
KW  - Bidirectional Encoder Representations from Transformers
KW  - BERT
KW  - generative pretrained transformer
KW  - GPT
KW  - United States
KW  - US
KW  - China
KW  - scoping review
KW  - Preferred Reporting Items for Systematic Reviews and Meta-Analyses
KW  - PRISMA
KW  - decision support
KW  - workflow efficiency
KW  - risk
KW  - ethics
KW  - education
KW  - communication
KW  - medical training
KW  - physician
KW  - health literacy
KW  - emergency care
AB  - Background
Artificial intelligence (AI), more specifically large language models (LLMs), holds significant potential in revolutionizing emergency care delivery by optimizing clinical workflows and enhancing the quality of decision-making. Although enthusiasm for integrating LLMs into emergency medicine (EM) is growing, the existing literature is characterized by a disparate collection of individual studies, conceptual analyses, and preliminary implementations. Given these complexities and gaps in understanding, a cohesive framework is needed to comprehend the existing body of knowledge on the application of LLMs in EM.
Objective
Given the absence of a comprehensive framework for exploring the roles of LLMs in EM, this scoping review aims to systematically map the existing literature on LLMs’ potential applications within EM and identify directions for future research. Addressing this gap will allow for informed advancements in the field.
Methods
Using PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) criteria, we searched Ovid MEDLINE, Embase, Web of Science, and Google Scholar for papers published between January 2018 and August 2023 that discussed LLMs’ use in EM. We excluded other forms of AI. A total of 1994 unique titles and abstracts were screened, and each full-text paper was independently reviewed by 2 authors. Data were abstracted independently, and 5 authors performed a collaborative quantitative and qualitative synthesis of the data.
Results
A total of 43 papers were included. Studies were predominantly from 2022 to 2023 and conducted in the United States and China. We uncovered four major themes: (1) clinical decision-making and support was highlighted as a pivotal area, with LLMs playing a substantial role in enhancing patient care, notably through their application in real-time triage, allowing early recognition of patient urgency; (2) efficiency, workflow, and information management demonstrated the capacity of LLMs to significantly boost operational efficiency, particularly through the automation of patient record synthesis, which could reduce administrative burden and enhance patient-centric care; (3) risks, ethics, and transparency were identified as areas of concern, especially regarding the reliability of LLMs’ outputs, and specific studies highlighted the challenges of ensuring unbiased decision-making amidst potentially flawed training data sets, stressing the importance of thorough validation and ethical oversight; and (4) education and communication possibilities included LLMs’ capacity to enrich medical training, such as through using simulated patient interactions that enhance communication skills.
Conclusions
LLMs have the potential to fundamentally transform EM, enhancing clinical decision-making, optimizing workflows, and improving patient outcomes. This review sets the stage for future advancements by identifying key research areas: prospective validation of LLM applications, establishing standards for responsible use, understanding provider and patient perceptions, and improving physicians’ AI literacy. Effective integration of LLMs into EM will require collaborative efforts and thorough evaluation to ensure these technologies can be safely and effectively applied.
ER  - 

TY  - JOUR
T1  - Future applications of generative large language models: A data-driven case study on ChatGPT
AU  - Chiarello, Filippo
AU  - Giordano, Vito
AU  - Spada, Irene
AU  - Barandoni, Simone
AU  - Fantoni, Gualtiero
JO  - Technovation
VL  - 133
SP  - 103002
PY  - 2024
DA  - 2024/05/01/
SN  - 0166-4972
DO  - https://doi.org/10.1016/j.technovation.2024.103002
UR  - https://www.sciencedirect.com/science/article/pii/S016649722400052X
KW  - Generative artificial intelligence
KW  - Generative large language models
KW  - ChatGPT
KW  - Social media analysis
KW  - Technology adoption
KW  - Emerging technologies
AB  - This study delves into the evolving role of generative Large Language Models (LLMs). We develop a data-driven approach to collect and analyse tasks that users are asking to generative LLMs. Thanks to the focus on tasks this paper contributes to give a quantitative and granular understanding of the potential influence of LLMs in different business areas. Utilizing a dataset comprising over 3.8 million tweets, we identify and cluster 31,747 unique tasks, with a specific case study on ChatGPT. To reach this goal, the proposed method combines two Natural Language Processing (NLP) Techniques, Named Entity Recognition (NER) and BERTopic. The combination makes it possible to collect granular tasks of LLMs (NER) and clusters them in business areas (BERTopic). Our findings reveal a wide spectrum of applications, from programming assistance to creative content generation, highlighting LLM's versatility. The analysis highlighted six emerging areas of application for ChatGPT: human resources, programming, social media, office automation, search engines, education. The study also examines the implications of these findings for innovation management, proposing a research agenda to explore the intersection of the identified areas, with four stages of the innovation process: idea generation, screening/idea selection, development, and diffusion/sales/marketing.
ER  - 

TY  - JOUR
T1  - LKPNR: Large Language Models and Knowledge Graph for Personalized News Recommendation Framework
AU  - Chen, Hao
AU  - Xie, Runfeng
AU  - Cui, Xiangyang
AU  - Yan, Zhou
AU  - Wang, Xin
AU  - Xuan, Zhanwei
AU  - Zhang, Kai
JO  - Computers, Materials and Continua
VL  - 79
IS  - 3
SP  - 4283
EP  - 4296
PY  - 2024
DA  - 2024/06/20/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.049129
UR  - https://www.sciencedirect.com/science/article/pii/S1546221824000225
KW  - Large language models
KW  - news recommendation
KW  - knowledge graphs (KG)
AB  - Accurately recommending candidate news to users is a basic challenge of personalized news recommendation systems. Traditional methods are usually difficult to learn and acquire complex semantic information in news texts, resulting in unsatisfactory recommendation results. Besides, these traditional methods are more friendly to active users with rich historical behaviors. However, they can not effectively solve the long tail problem of inactive users. To address these issues, this research presents a novel general framework that combines Large Language Models (LLM) and Knowledge Graphs (KG) into traditional methods. To learn the contextual information of news text, we use LLMs’ powerful text understanding ability to generate news representations with rich semantic information, and then, the generated news representations are used to enhance the news encoding in traditional methods. In addition, multi-hops relationship of news entities is mined and the structural information of news is encoded using KG, thus alleviating the challenge of long-tail distribution. Experimental results demonstrate that compared with various traditional models, on evaluation indicators such as AUC, MRR, nDCG@5 and nDCG@10, the framework significantly improves the recommendation performance. The successful integration of LLM and KG in our framework has established a feasible way for achieving more accurate personalized news recommendation. Our code is available at https://github.com/Xuan-ZW/LKPNR.
ER  - 

TY  - JOUR
T1  - Can large language models reason about medical questions?
AU  - Liévin, Valentin
AU  - Hother, Christoffer Egeberg
AU  - Motzfeldt, Andreas Geert
AU  - Winther, Ole
JO  - Patterns
VL  - 5
IS  - 3
SP  - 100943
PY  - 2024
DA  - 2024/03/08/
SN  - 2666-3899
DO  - https://doi.org/10.1016/j.patter.2024.100943
UR  - https://www.sciencedirect.com/science/article/pii/S2666389924000424
KW  - large language models
KW  - question answering
KW  - medical
KW  - GPT-3.5
KW  - Llama 2
KW  - open source
KW  - MedQA
KW  - prompt engineering
KW  - uncertainty quantification
KW  - machine learning
AB  - Summary
Although large language models often produce impressive outputs, it remains unclear how they perform in real-world scenarios requiring strong reasoning skills and expert domain knowledge. We set out to investigate whether closed- and open-source models (GPT-3.5, Llama 2, etc.) can be applied to answer and reason about difficult real-world-based questions. We focus on three popular medical benchmarks (MedQA-US Medical Licensing Examination [USMLE], MedMCQA, and PubMedQA) and multiple prompting scenarios: chain of thought (CoT; think step by step), few shot, and retrieval augmentation. Based on an expert annotation of the generated CoTs, we found that InstructGPT can often read, reason, and recall expert knowledge. Last, by leveraging advances in prompt engineering (few-shot and ensemble methods), we demonstrated that GPT-3.5 not only yields calibrated predictive distributions but also reaches the passing score on three datasets: MedQA-USMLE (60.2%), MedMCQA (62.7%), and PubMedQA (78.2%). Open-source models are closing the gap: Llama 2 70B also passed the MedQA-USMLE with 62.5% accuracy.
ER  - 

TY  - JOUR
T1  - Retrieval augmentation of large language models for lay language generation
AU  - Guo, Yue
AU  - Qiu, Wei
AU  - Leroy, Gondy
AU  - Wang, Sheng
AU  - Cohen, Trevor
JO  - Journal of Biomedical Informatics
VL  - 149
SP  - 104580
PY  - 2024
DA  - 2024/01/01/
SN  - 1532-0464
DO  - https://doi.org/10.1016/j.jbi.2023.104580
UR  - https://www.sciencedirect.com/science/article/pii/S1532046423003015
KW  - Large language models
KW  - Retrieval-augmented model
KW  - Lay language summary
KW  - Background explanation
KW  - Text generation
AB  - The complex linguistic structures and specialized terminology of expert-authored content limit the accessibility of biomedical literature to the general public. Automated methods have the potential to render this literature more interpretable to readers with different educational backgrounds. Prior work has framed such lay language generation as a summarization or simplification task. However, adapting biomedical text for the lay public includes the additional and distinct task of background explanation: adding external content in the form of definitions, motivation, or examples to enhance comprehensibility. This task is especially challenging because the source document may not include the required background knowledge. Furthermore, background explanation capabilities have yet to be formally evaluated, and little is known about how best to enhance them. To address this problem, we introduce Retrieval-Augmented Lay Language (RALL) generation, which intuitively fits the need for external knowledge beyond that in expert-authored source documents. In addition, we introduce CELLS, the largest (63k pairs) and broadest-ranging (12 journals) parallel corpus for lay language generation. To evaluate RALL, we augmented state-of-the-art text generation models with information retrieval of either term definitions from the UMLS and Wikipedia, or embeddings of explanations from Wikipedia documents. Of these, embedding-based RALL models improved summary quality and simplicity while maintaining factual correctness, suggesting that Wikipedia is a helpful source for background explanation in this context. We also evaluated the ability of both an open-source Large Language Model (Llama 2) and a closed-source Large Language Model (GPT-4) in background explanation, with and without retrieval augmentation. Results indicate that these LLMs can generate simplified content, but that the summary quality is not ideal. Taken together, this work presents the first comprehensive study of background explanation for lay language generation, paving the path for disseminating scientific knowledge to a broader audience. Our code and data are publicly available at: https://github.com/LinguisticAnomalies/pls_retrieval.
ER  - 

TY  - JOUR
T1  - Integrating chemistry knowledge in large language models via prompt engineering
AU  - Liu, Hongxuan
AU  - Yin, Haoyu
AU  - Luo, Zhiyao
AU  - Wang, Xiaonan
JO  - Synthetic and Systems Biotechnology
VL  - 10
IS  - 1
SP  - 23
EP  - 38
PY  - 2025
DA  - 2025/01/01/
SN  - 2405-805X
DO  - https://doi.org/10.1016/j.synbio.2024.07.004
UR  - https://www.sciencedirect.com/science/article/pii/S2405805X24001029
AB  - This paper presents a study on the integration of domain-specific knowledge in prompt engineering to enhance the performance of large language models (LLMs) in scientific domains. The proposed domain-knowledge embedded prompt engineering method outperforms traditional prompt engineering strategies on various metrics, including capability, accuracy, F1 score, and hallucination drop. The effectiveness of the method is demonstrated through case studies on complex materials including the MacMillan catalyst, paclitaxel, and lithium cobalt oxide. The results suggest that domain-knowledge prompts can guide LLMs to generate more accurate and relevant responses, highlighting the potential of LLMs as powerful tools for scientific discovery and innovation when equipped with domain-specific prompts. The study also discusses limitations and future directions for domain-specific prompt engineering development.
ER  - 

TY  - JOUR
T1  - Identifying social concerns in virtual reality technology through text mining and large language models, and prioritizing them with the fuzzy hierarchized analytic network process
AU  - Rezaei, Esmaeil
AU  - Mosallanezhad, Behzad
JO  - Computers and Electrical Engineering
VL  - 120
SP  - 109770
PY  - 2024
DA  - 2024/12/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2024.109770
UR  - https://www.sciencedirect.com/science/article/pii/S0045790624006979
KW  - Virtual reality
KW  - Latent semantic analysis
KW  - Hierarchized analytic network process
KW  - Large language models
KW  - Text mining
KW  - Multi-criteria decision making
KW  - Multi-attribute decision making
AB  - Virtual reality technology has rapidly gained popularity as an entertainment medium, drawing interest from diverse age groups. However, its widespread adoption depends on effectively addressing public concerns and achieving market acceptance. While some studies have acknowledged these concerns, a significant gap persists in comprehensive research that incorporates both individual and expert perspectives. Consequently, certain underlying social issues related to virtual reality systems remain unexplored and unprioritized. To address this gap, this paper proposes a methodology that utilizes Latent Semantic Analysis (LSA) to identify and assess social concerns from various sources, including user perspectives. Large Language Models (LLMs) assist in retrieving relevant chunks of articles during analysis, enhancing data quality. Furthermore, we introduce a novel decision-making tool, the Hierarchized Analytic Network Process (HANP) and its fuzzy form, to effectively rank these concerns. This approach addresses a limitation of the traditional Analytic Network Process (ANP), which can overemphasize dependent attributes, potentially leading to zero-weighted, less important attributes and making comparisons impossible. By prioritizing social concerns based on their significance, our approach aims to facilitate broader social acceptance of virtual reality technologies among the general public. To further demonstrate the advantages of our proposed approach, the results obtained from F-HANP (in situations where fuzzy judgments are available) and HANP are compared with other popular decision-making methods.
ER  - 

TY  - JOUR
T1  - Exploring Chinese EFL learners’ engagement with large language models: A self-determination theory perspective
AU  - Wang, Xiaochen
AU  - Wang, Siyi
JO  - Learning and Motivation
VL  - 87
SP  - 102014
PY  - 2024
DA  - 2024/08/01/
SN  - 0023-9690
DO  - https://doi.org/10.1016/j.lmot.2024.102014
UR  - https://www.sciencedirect.com/science/article/pii/S0023969024000560
KW  - EFL learners
KW  - Engagement
KW  - LLMs
KW  - SDT
KW  - Chinese context
AB  - Large language models (LLMs) greatly affect language learning, but research on Chinese EFL (English as a Foreign Language) learners’ engagement is limited. In this sense, the present study draws upon Self-Determination Theory (SDT) and employs a mixed-methods approach to explore how 210 Chinese EFL Learners engage with LLMs. Findings showed that most of the basic psychological needs (BPNs) play a critical role in predicting behavioral, cognitive, and emotional engagement. However, perceived autonomy did not emerge as a predictor for behavioral engagement, and perceived competence was not found to be a predictor for either behavioral engagement or cognitive engagement. Furthermore, our qualitative interviews showed that the influence of BPNs on EFL learners’ engagement with LLMs can be categorized into six thematic areas: self-directed learning empowerment, goal-oriented learning challenges, individual performance enhancement, limited knowledge advancement, collaborative learning access, and interpersonal connection gaps. The findings of this study could provide insights for foreign language teachers in their instructional design and for policymakers in formulating relevant policies.
ER  - 

TY  - JOUR
T1  - Evaluating Large Language Models for Arabic Sentiment Analysis: A Comparative Study Using Retrieval-Augmented Generation
AU  - Khaled, Salma
AU  - Mohamed, Ensaf Hussein
AU  - Medhat, Walaa
JO  - Procedia Computer Science
VL  - 244
SP  - 363
EP  - 370
PY  - 2024
DA  - 2024/01/01/
T2  - 6th International Conference on AI in Computational Linguistics
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.10.210
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924030114
KW  - Arabic Sentiment Analysis
KW  - Large Language Models
KW  - Retrieval Augmented Generation
KW  - ASAD
KW  - ArSarcasm-v2
KW  - semEval
AB  - Sentiment Analysis (SA) is a crucial task in natural language processing. There are numerous studies devoted to this field specially with emerging use of encoder transformers and generative Large Language Models (LLMs). Transformer based models like BERT are often used for sentiment analysis. However, this article examines the performance of the latest generative generative LLMs in Arabic Sentiment Analysis (ASA) using Retrieval-Augmented Generation (RAG) architecture. We evaluated these models using the ASAD, ArSarcasm-v2, and SemEval datasets. Our experimental studies revealed challenges due to dataset imbalances and misclassified neutral labels, which impacted the effectiveness of fine-tuning. By removing the neutral class, significant improvements in model performance were observed across all datasets, with F1-scores increasing by 17%, 18%, and 18% on ASAD, ArSarcasm-v2, and SemEval, respectively.
ER  - 

TY  - JOUR
T1  - Generative AI and large language models: A new frontier in reverse vaccinology
AU  - Hayawi, Kadhim
AU  - Shahriar, Sakib
AU  - Alashwal, Hany
AU  - Serhani, Mohamed Adel
JO  - Informatics in Medicine Unlocked
VL  - 48
SP  - 101533
PY  - 2024
DA  - 2024/01/01/
SN  - 2352-9148
DO  - https://doi.org/10.1016/j.imu.2024.101533
UR  - https://www.sciencedirect.com/science/article/pii/S2352914824000893
KW  - Reverse vaccinology
KW  - Large language models (LLMs)
KW  - AI
KW  - Generative AI
KW  - Vaccine candidate identification
KW  - AI ethics
KW  - Vaccines
AB  - Reverse vaccinology is an emerging concept in the field of vaccine development as it facilitates the identification of potential vaccine candidates. Biomedical research has been revolutionized with the recent innovations in Generative Artificial Intelligence (AI) and Large Language Models (LLMs). The intersection of these two technologies is explored in this study. In this study, the impact of Generative AI and LLMs in the field of vaccinology is explored. Through a comprehensive analysis of existing research, prospective use cases, and an experimental case study, this research highlights that LLMs and Generative AI have the potential to enhance the efficiency and accuracy of vaccine candidate identification. This work also discusses the ethical and privacy challenges, such as data consent and potential biases, raised by such applications that require careful consideration. This study paves the way for experts, researchers, and policymakers to further investigate the role and impact of Generative AI and LLM in vaccinology and medicine.
ER  - 

TY  - JOUR
T1  - The “David Vs Goliath” Study: Application of Large Language Models (LLM) for Automatic Medical Information Retrieval from Multiple Data Sources to Accelerate Clinical and Translational Research in Hematology
AU  - Delleani, Mattia
AU  - D'Amico, Saverio
AU  - Sauta, Elisabetta
AU  - Asti, Gianluca
AU  - Zazzetti, Elena
AU  - Campagna, Alessia
AU  - Lanino, Luca
AU  - Maggioni, Giulia
AU  - Grondelli, Maria Chiara
AU  - Forcina Barrero, Alessandro
AU  - Morandini, Pierandrea
AU  - Ubezio, Marta
AU  - Todisco, Gabriele
AU  - Russo, Antonio
AU  - Tentori, Cristina Astrid
AU  - Buizza, Alessandro
AU  - Bonometti, Arturo
AU  - Lancellotti, Cesare
AU  - Di Tommaso, Luca
AU  - Rahal, Daoud
AU  - Bicchieri, Marilena
AU  - Savevski, Victor
AU  - Santoro, Armando
AU  - Santini, Valeria
AU  - Sole, Francesc
AU  - Platzbecker, Uwe
AU  - Fenaux, Pierre
AU  - Diez-Campelo, Maria
AU  - Komrokji, Rami S.
AU  - Garcia-Manero, Guillermo
AU  - Haferlach, Torsten
AU  - Kordasti, Shahram
AU  - Zeidan, Amer M.
AU  - Castellani, Gastone
AU  - Della Porta, Matteo Giovanni
JO  - Blood
VL  - 144
SP  - 3597
PY  - 2024
DA  - 2024/11/05/
T2  - 66th ASH Annual Meeting Abstracts
SN  - 0006-4971
DO  - https://doi.org/10.1182/blood-2024-205621
UR  - https://www.sciencedirect.com/science/article/pii/S0006497124063493
AB  - Background. The innovation process in hematology requires access to a large amount of healthcare data. However, 97% of patient data produced by hospitals remains unused (Source: Deloitte, Health Data, 2023), primarily due to privacy limitations, lack of data harmonization from different sources, and the unstructured and dispersed nature of the information. Large Language Models (LLM) are computational models capable of performing general-purpose language generation and other natural language processing tasks. These models acquire these abilities by learning statistical relationships from vast amounts of text through a computationally intensive self-supervised and semi-supervised training process. LLMs have been increasingly utilized in healthcare to enhance diagnostics, streamline patient interactions, and improve overall clinical workflows. In this project, we analyze the potential of Artificial Intelligence (AI) solutions based on LLM for data retrieval, extraction and generation to create standardized datasets to accelerate clinical and translational research in blood diseases in hematology. Aims. The “David vs Goliath” study was conducted by Synthema EU consortium with the following aims to: 1) develop AI solution leveraging LLM for information retrieval, extraction and generation of research-ready datasets from multiple medical sources; 2) evaluate clinical and statistical fidelity of AI-retrieved dataset through a specific Validation Framework (VF); 3) validate the reliability of AI-retrieved dataset to build personalized prognostic models. Methods. We proposed ARISTOTELES an Automatic Retrieval Information System TO acceleraTE clinical and translationaL research in hEmatological malignancieS. This solution has three main components: a Retrieval-Augmented Generation (RAG) system for information retrieval; an LLM for data extraction and a Generative Pretrained Transformer (GPT) for missing data inference. The RAG component, also leveraging a dedicated LLM model, was implemented to search information across multiple data sources from the Humanitas Research Hospital DataLake (a fully privacy compliant environment) and to enhance the quality of retrieved information. The information provided by RAG was then extracted by a second hematological-tuned LLM model into a structured dataset in common data model format. Finally, the GPT model, trained on hematological data, was then used to generate complete data, conditioned on partially extracted patients' information. Results. The original dataset (Goliath) comprises 1167 patients with myeloid neoplasms (MN) from Humanitas Research Hospital, including multiple layers of information with comprehensive demographic, clinical and genomic data (cytogenetics and mutational screening) alongside treatment and outcome. The AI-retrieved dataset (David) was generated by applying ARISTOTELES on medical records from the same MN patients. The comparison of the two datasets was performed by a specific validation framework (based on PMID:38875514). Distributions and correlations for clinical, demographic, genomic and cytogenetic in both datasets were comparable with 91% of fidelity. Mutation distribution and pairwise association among genes and/or cytogenetics abnormalities resulted in 90.1% of fidelity. No significant statistical difference between the two datasets has been observed by comparing the survival curves with a Kaplan-Meier model with a log-rank test in patients stratified according to clinical labels. Finally, we performed Cox proportional hazards analyses (Cox-PH) including clinical and genomic information from the David vs Goliath datasets to compare their performance (concordance index, CI). Considering overall survival as a clinical endpoint the CI of Cox-PH models was 0.75 and 0.74 respectively. Conclusion. ARISTOTELES solution allows automatic information retrieval, extraction and structuring of complex multimodal healthcare data. AI-retrieved data (David) resulted in high clinical and statistical fidelity with respect to the original dataset (Goliath). Overall, this results in increasing access to healthcare data and reducing human effort required for data collection tasks, thereby accelerating clinical research in hematology.
ER  - 

TY  - JOUR
T1  - Use of Large Language Models to Identify Surveillance Colonoscopy Intervals—A Feasibility Study
AU  - Acharya, Vedant
AU  - Kumaresan, Vignesh
AU  - England, Jonathan
AU  - Mehta, Shivan
AU  - Sussman, Daniel
AU  - Deshpande, Amar
JO  - Gastroenterology
VL  - 168
IS  - 2
SP  - 382
EP  - 384.e4
PY  - 2025
DA  - 2025/02/01/
SN  - 0016-5085
DO  - https://doi.org/10.1053/j.gastro.2024.09.032
UR  - https://www.sciencedirect.com/science/article/pii/S0016508524055380
ER  - 

TY  - JOUR
T1  - An Adversarial Machine Learning Approach on Securing Large Language Model with Vigil, an Open-Source Initiative
AU  - Pokhrel, Kushal
AU  - Sanin, Cesar
AU  - Hossain Sakib, Md. Kowssar
AU  - Islam, Md Rafiqul
AU  - Szczerbicki, Edward
JO  - Procedia Computer Science
VL  - 246
SP  - 686
EP  - 695
PY  - 2024
DA  - 2024/01/01/
T2  - 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.09.486
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924025316
KW  - Adversarial Machine Learning
KW  - Large Language Model
KW  - Information Security
KW  - Prompt Injection
KW  - Synthetic Prompt Generation
KW  - Natural Language Processing
AB  - Several security concerns and efforts to breach system security and prompt safety concerns have been brought to light as a result of the expanding use of LLMs. These vulnerabilities are evident and LLM models have been showing many signs of hallucination, repetitive content generation, and biases, which makes them vulnerable to malicious prompts that raise substantial concerns in regard to the dependability and efficiency of such models. It is vital to have a complete grasp of the complex behaviours of malicious attackers in order to build effective strategies for protecting modern artificial intelligence (AI) systems through the development of effective tactics. The purpose of this study is to look into some of these aspects and propose a method for preventing devastating possibilities and protecting LLMs from potential threats that attackers may pose. Vigil is an open-source LLM prompt security scanner, that is accessible as a Python library and REST API, specifically to solve these problems by employing a sophisticated adversarial machine-learning algorithm. The entire objective of this study is to make use of Vigil as a security scanner. and asses its efficiency. In this case study, we shed some light on Vigil, which effectively recognises and helps LLM prompts by identifying two varieties of threats: malicious and benign.
ER  - 

TY  - JOUR
T1  - Empirical study on fine-tuning pre-trained large language models for fault diagnosis of complex systems
AU  - Zheng, Shuwen
AU  - Pan, Kai
AU  - Liu, Jie
AU  - Chen, Yunxia
JO  - Reliability Engineering & System Safety
VL  - 252
SP  - 110382
PY  - 2024
DA  - 2024/12/01/
SN  - 0951-8320
DO  - https://doi.org/10.1016/j.ress.2024.110382
UR  - https://www.sciencedirect.com/science/article/pii/S095183202400454X
KW  - prognosis and health management
KW  - fault diagnosis
KW  - large language model
KW  - complex systems
KW  - high-speed train
KW  - chemical plant
AB  - With increasing complexity and interconnectivity of the modern industrial systems, effectively diagnosing faults is a core step to Prognostic and Health Management (PHM). Language models, particularly Large Language Models (LLMs) that pre-trained on massive corpora, have demonstrated remarkable capabilities in Natural Language Processing (NLP) and its related downstream tasks. However, how to leverage these models for facilitating system fault diagnosis and verify its effectiveness is rarely explored. This paper incorporates the potential comprehension ability of pre-trained LLMs, and investigates the efficacy of fine-tuning LLMs for realizing efficient system fault diagnosis. The experiments conducted in this study involve both open-source and closed-source models, and utilize a simulation and a real fault diagnosis dataset. We find that these models consistently achieve high performance across various metrics compared to the baselines. Additionally, qualitative and quantitative analysis is performed to investigate several aspects of the approach, such as the impact of dataset size, data normalization, missing values and explainability of the diagnosis, further showcasing the potential as well as limitations of the approach.
ER  - 

TY  - JOUR
T1  - Integrating human expertise & automated methods for a dynamic and multi-parametric evaluation of large language models’ feasibility in clinical decision-making
AU  - Sblendorio, Elena
AU  - Dentamaro, Vincenzo
AU  - Lo Cascio, Alessio
AU  - Germini, Francesco
AU  - Piredda, Michela
AU  - Cicolini, Giancarlo
JO  - International Journal of Medical Informatics
VL  - 188
SP  - 105501
PY  - 2024
DA  - 2024/08/01/
SN  - 1386-5056
DO  - https://doi.org/10.1016/j.ijmedinf.2024.105501
UR  - https://www.sciencedirect.com/science/article/pii/S1386505624001643
KW  - LLM’s feasibility
KW  - AI routine integration
KW  - Methodology
KW  - Clinical decision making
KW  - Healthcare innovation
KW  - Nursing informatics
KW  - Safety
KW  - Multidisciplinary approach
KW  - Multi-parametric analysis
AB  - Background
Recent enhancements in Large Language Models (LLMs) such as ChatGPT have exponentially increased user adoption. These models are accessible on mobile devices and support multimodal interactions, including conversations, code generation, and patient image uploads, broadening their utility in providing healthcare professionals with real-time support for clinical decision-making. Nevertheless, many authors have highlighted serious risks that may arise from the adoption of LLMs, principally related to safety and alignment with ethical guidelines.
Objective
To address these challenges, we introduce a novel methodological approach designed to assess the specific feasibility of adopting LLMs within a healthcare area, with a focus on clinical nursing, evaluating their performance and thereby directing their choice. Emphasizing LLMs’ adherence to scientific advancements, this approach prioritizes safety and care personalization, according to the “Organization for Economic Co-operation and Development” frameworks for responsible AI. Moreover, its dynamic nature is designed to adapt to future evolutions of LLMs.
Method
Through integrating advanced multidisciplinary knowledge, including Nursing Informatics, and aided by a prospective literature review, seven key domains and specific evaluation items were identified as follows:1.State of the Art Alignment & Safety.2.Focus, Accuracy & Management of Prompt Ambiguity.3.Data Integrity, Data Security, Ethics & Sustainability, in accordance with OECD Recommendations for Responsible AI.4.Temporal Variability of Responses (Consistency)5.Adaptation to specific standardized terminology and Classifications for healthcare professionals.6.General Capabilities: Post User Feedback Self-Evolution Capability and Organization in Chapters.7.Ability to Drive Evolution in Healthcare.A Peer Review by experts in Nursing and AI was performed, ensuring scientific rigor and breadth of insights for an essential, reproducible, and coherent methodological approach. By means of a 7-point Likert scale, thresholds are defined in order to classify LLMs as “unusable”, “usable with high caution”, and “recommended” categories. Nine state of the art LLMs were evaluated using this methodology in clinical oncology nursing decision-making, producing preliminary results. Gemini Advanced, Anthropic Claude 3 and ChatGPT 4 achieved the minimum score of the State of the Art Alignment & Safety domain for classification as “recommended”, being also endorsed across all domains. LLAMA 3 70B and ChatGPT 3.5 were classified as “usable with high caution.” Others were classified as unusable in this domain.
Conclusion
The identification of a recommended LLM for a specific healthcare area, combined with its critical, prudent, and integrative use, can support healthcare professionals in decision-making processes.
ER  - 

TY  - JOUR
T1  - Mitigating Cognitive Biases in Clinical Decision-Making Through Multi-Agent Conversations Using Large Language Models: Simulation Study
AU  - Ke, Yuhe
AU  - Yang, Rui
AU  - Lie, Sui An
AU  - Lim, Taylor Xin Yi
AU  - Ning, Yilin
AU  - Li, Irene
AU  - Abdullah, Hairil Rizal
AU  - Ting, Daniel Shu Wei
AU  - Liu, Nan
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/59439
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124008124
KW  - clinical decision-making
KW  - cognitive bias
KW  - generative artificial intelligence
KW  - large language model
KW  - multi-agent
AB  - Background
Cognitive biases in clinical decision-making significantly contribute to errors in diagnosis and suboptimal patient outcomes. Addressing these biases presents a formidable challenge in the medical field.
Objective
This study aimed to explore the role of large language models (LLMs) in mitigating these biases through the use of the multi-agent framework. We simulate the clinical decision-making processes through multi-agent conversation and evaluate its efficacy in improving diagnostic accuracy compared with humans.
Methods
A total of 16 published and unpublished case reports where cognitive biases have resulted in misdiagnoses were identified from the literature. In the multi-agent framework, we leveraged GPT-4 (OpenAI) to facilitate interactions among different simulated agents to replicate clinical team dynamics. Each agent was assigned a distinct role: (1) making the final diagnosis after considering the discussions, (2) acting as a devil’s advocate to correct confirmation and anchoring biases, (3) serving as a field expert in the required medical subspecialty, (4) facilitating discussions to mitigate premature closure bias, and (5) recording and summarizing findings. We tested varying combinations of these agents within the framework to determine which configuration yielded the highest rate of correct final diagnoses. Each scenario was repeated 5 times for consistency. The accuracy of the initial diagnoses and the final differential diagnoses were evaluated, and comparisons with human-generated answers were made using the Fisher exact test.
Results
A total of 240 responses were evaluated (3 different multi-agent frameworks). The initial diagnosis had an accuracy of 0% (0/80). However, following multi-agent discussions, the accuracy for the top 2 differential diagnoses increased to 76% (61/80) for the best-performing multi-agent framework (Framework 4-C). This was significantly higher compared with the accuracy achieved by human evaluators (odds ratio 3.49; P=.002).
Conclusions
The multi-agent framework demonstrated an ability to re-evaluate and correct misconceptions, even in scenarios with misleading initial investigations. In addition, the LLM-driven, multi-agent conversation framework shows promise in enhancing diagnostic accuracy in diagnostically challenging medical scenarios.
ER  - 

TY  - JOUR
T1  - Selective privacy-preserving framework for large language models fine-tuning
AU  - Wang, Teng
AU  - Zhai, Lindong
AU  - Yang, Tengfei
AU  - Luo, Zhucheng
AU  - Liu, Shuanggen
JO  - Information Sciences
VL  - 678
SP  - 121000
PY  - 2024
DA  - 2024/09/01/
SN  - 0020-0255
DO  - https://doi.org/10.1016/j.ins.2024.121000
UR  - https://www.sciencedirect.com/science/article/pii/S0020025524009149
KW  - Large language models
KW  - Fine-tuning
KW  - Local differential privacy
KW  - Selective privacy protection
AB  - Fine-tuning pre-trained large language models (LLMs) helps various downstream tasks, but brings serious privacy leaks when relying on large amounts of data for training. Differentially private stochastic gradient descent (DPSGD) has been designed to introduce noise during model updates to prevent privacy leaks. Nevertheless, fine-tuning LLMs via DPSGD limits the model utility since heavy perturbations are introduced on large high-dimensional gradients. Besides, existing privacy-preserving mechanisms directly perturb all tokens of the input sentences, which are too pessimistic to achieve good model performance. Therefore, this paper researches a selective privacy-preserving framework for fine-tuning LLMs. We propose a first-of-its-kind privacy notion called selective sequence local differential privacy (S-SeqLDP), which provides guarantees of indistinguishability only for the secret part of the sequences. Furthermore, we design a novel framework called SLDP-FT that enables S-SeqLDP-compliant large language model fine-tuning by perturbing the forward-pass embeddings with selective noises. We innovatively investigate the privacy forward weight that determines the noise magnitude of achieving selective privacy protection. Extensive experiments on three tasks demonstrate that our SLDP-FT achieves better model accuracy than state-of-the-art techniques when providing the same level of privacy protection.
ER  - 

TY  - JOUR
T1  - Enhancing user prompt confidentiality in Large Language Models through advanced differential encryption
AU  - Gupta, Brij B.
AU  - Gaurav, Akshat
AU  - Arya, Varsha
AU  - Alhalabi, Wadee
AU  - Alsalman, Dheyaaldin
AU  - Vijayakumar, P.
JO  - Computers and Electrical Engineering
VL  - 116
SP  - 109215
PY  - 2024
DA  - 2024/05/01/
SN  - 0045-7906
DO  - https://doi.org/10.1016/j.compeleceng.2024.109215
UR  - https://www.sciencedirect.com/science/article/pii/S0045790624001435
KW  - Cryptographic privacy
KW  - Large Language Models
KW  - Data anonymization
KW  - Secure AI framework
KW  - Personal data protection
AB  - In the era of artificial intelligence (AI) advancements heralded by Large Language Models (LLMs) like GPT-3, the capacity to parse and generate human-like text brings to light substantial privacy concerns. These arise notably from LLMs’ reliance on vast datasets often laden with personal information, underscoring the potential for inadvertent memorization and disclosure of sensitive data. Addressing these pivotal privacy concerns, our research introduces a novel two-fold approach aimed at bolstering the confidentiality and security of user data in LLM applications. Firstly, we deploy advanced cryptographic techniques, incorporating bespoke encryption and hashing protocols, to preprocess user data. This strategy effectively anonymizes personal identifiers prior to their processing by LLMs, directly tackling the challenges of sensitive information exposure. Concurrently, our methodology encompasses a secure mutual authentication protocol utilizing lightweight cryptographic measures. This ensures that system interactions are strictly reserved for authenticated users, thereby enhancing overall data security. Collectively, our approach not only preserves the utility of data for AI tasks but also fortifies the privacy framework surrounding LLMs, significantly reducing the likelihood of privacy breaches and steering AI development towards a more secure and ethically grounded future.
ER  - 

TY  - JOUR
T1  - Summary of ChatGPT-Related research and perspective towards the future of large language models
AU  - Liu, Yiheng
AU  - Han, Tianle
AU  - Ma, Siyuan
AU  - Zhang, Jiayue
AU  - Yang, Yuanyuan
AU  - Tian, Jiaming
AU  - He, Hao
AU  - Li, Antong
AU  - He, Mengshen
AU  - Liu, Zhengliang
AU  - Wu, Zihao
AU  - Zhao, Lin
AU  - Zhu, Dajiang
AU  - Li, Xiang
AU  - Qiang, Ning
AU  - Shen, Dingang
AU  - Liu, Tianming
AU  - Ge, Bao
JO  - Meta-Radiology
VL  - 1
IS  - 2
SP  - 100017
PY  - 2023
DA  - 2023/09/01/
SN  - 2950-1628
DO  - https://doi.org/10.1016/j.metrad.2023.100017
UR  - https://www.sciencedirect.com/science/article/pii/S2950162823000176
AB  - This paper presents a comprehensive survey of ChatGPT-related (GPT-3.5 and GPT-4) research, state-of-the-art large language models (LLM) from the GPT series, and their prospective applications across diverse domains. Indeed, key innovations such as large-scale pre-training that captures knowledge across the entire world wide web, instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) have played significant roles in enhancing LLMs' adaptability and performance. We performed an in-depth analysis of 194 relevant papers on arXiv, encompassing trend analysis, word cloud representation, and distribution analysis across various application domains. The findings reveal a significant and increasing interest in ChatGPT-related research, predominantly centered on direct natural language processing applications, while also demonstrating considerable potential in areas ranging from education and history to mathematics, medicine, and physics. This study endeavors to furnish insights into ChatGPT's capabilities, potential implications, ethical concerns, and offer direction for future advancements in this field.
ER  - 

TY  - JOUR
T1  - Inherent Bias in Large Language Models: A Random Sampling Analysis
AU  - Ayoub, Noel F.
AU  - Balakrishnan, Karthik
AU  - Ayoub, Marc S.
AU  - Barrett, Thomas F.
AU  - David, Abel P.
AU  - Gray, Stacey T.
JO  - Mayo Clinic Proceedings: Digital Health
VL  - 2
IS  - 2
SP  - 186
EP  - 191
PY  - 2024
DA  - 2024/06/01/
SN  - 2949-7612
DO  - https://doi.org/10.1016/j.mcpdig.2024.03.003
UR  - https://www.sciencedirect.com/science/article/pii/S2949761224000208
AB  - There are mounting concerns regarding inherent bias, safety, and tendency toward misinformation of large language models (LLMs), which could have significant implications in health care. This study sought to determine whether generative artificial intelligence (AI)-based simulations of physicians making life-and-death decisions in a resource-scarce environment would demonstrate bias. Thirteen questions were developed that simulated physicians treating patients in resource-limited environments. Through a random sampling of simulated physicians using OpenAI’s generative pretrained transformer (GPT-4), physicians were tasked with choosing only 1 patient to save owing to limited resources. This simulation was repeated 1000 times per question, representing 1000 unique physicians and patients each. Patients and physicians spanned a variety of demographic characteristics. All patients had similar a priori likelihood of surviving the acute illness. Overall, simulated physicians consistently demonstrated racial, gender, age, political affiliation, and sexual orientation bias in clinical decision-making. Across all demographic characteristics, physicians most frequently favored patients with similar demographic characteristics as themselves, with most pairwise comparisons showing statistical significance (P<.05). Nondescript physicians favored White, male, and young demographic characteristics. The male doctor gravitated toward the male, White, and young, whereas the female doctor typically preferred female, young, and White patients. In addition to saving patients with their own political affiliation, Democratic physicians favored Black and female patients, whereas Republicans preferred White and male demographic characteristics. Heterosexual and gay/lesbian physicians frequently saved patients of similar sexual orientation. Overall, publicly available chatbot LLMs demonstrate significant biases, which may negatively impact patient outcomes if used to support clinical care decisions without appropriate precautions.
ER  - 

TY  - JOUR
T1  - Large language models for air transportation: A critical review
AU  - Liu, Yucheng
JO  - Journal of the Air Transport Research Society
VL  - 2
SP  - 100024
PY  - 2024
DA  - 2024/06/01/
SN  - 2941-198X
DO  - https://doi.org/10.1016/j.jatrs.2024.100024
UR  - https://www.sciencedirect.com/science/article/pii/S2941198X24000356
KW  - Large language models
KW  - Air transportation
KW  - Review
KW  - Challenges
AB  - In the past decade, Artificial Intelligence (AI) has contributed to the improvement of various aviation aspects, including flight plan optimization, the development of autonomous systems, performing predictive analytics, as well as in passenger / crew assistance systems. The latest AI technology to potentially revolutionize air transportation are so-called Large Language Models (LLMs), which have an outstanding ability to process and generate human-like text. The application areas for LLMs cover nearly all aspects of air transportation, through language processing, content generation, and problem solving. In this study, we discuss the potential of this impact with two major contributions. First, we have performed an experimental evaluation of twelve commonly-used LLMs concerning their performance of air transportation related subjects, covering fact retrieval, complex reasoning abilities, and explanation tasks. Second, we have performed a survey among graduate students at Beihang University, a leading aviation university in China, to explore the experiences and uses of LLMs. We believe that our study makes a significant contribution towards the dissemination and application of LLMs in the air transportation domain.
ER  - 

TY  - JOUR
T1  - Context is everything in regulatory application of large language models (LLMs)
AU  - Tong, Weida
AU  - Renaudin, Michael
JO  - Drug Discovery Today
VL  - 29
IS  - 4
SP  - 103916
PY  - 2024
DA  - 2024/04/01/
SN  - 1359-6446
DO  - https://doi.org/10.1016/j.drudis.2024.103916
UR  - https://www.sciencedirect.com/science/article/pii/S1359644624000412
ER  - 

TY  - JOUR
T1  - Artificial Intelligence Large Language Models Address Anterior Cruciate Ligament Reconstruction: Superior Clarity and Completeness by Gemini Compared With ChatGPT-4 in Response to American Academy of Orthopaedic Surgeons Clinical Practice Guidelines
AU  - Quinn, Matthew
AU  - Milner, John D.
AU  - Schmitt, Phillip
AU  - Morrissey, Patrick
AU  - Lemme, Nicholas
AU  - Marcaccio, Stephen
AU  - DeFroda, Steven
AU  - Tabaddor, Ramin
AU  - Owens, Brett D.
JO  - Arthroscopy: The Journal of Arthroscopic & Related Surgery
PY  - 2024
DA  - 2024/09/21/
SN  - 0749-8063
DO  - https://doi.org/10.1016/j.arthro.2024.09.020
UR  - https://www.sciencedirect.com/science/article/pii/S0749806324007369
AB  - Purpose
To assess the ability of ChatGPT-4 and Gemini to generate accurate and relevant responses to the 2022 American Academy of Orthopaedic Surgeons (AAOS) Clinical Practice Guidelines (CPG) for anterior cruciate ligament reconstruction (ACLR).
Methods
Responses from ChatGPT-4 and Gemini to prompts derived from all 15 AAOS guidelines were evaluated by 7 fellowship-trained orthopaedic sports medicine surgeons using a structured questionnaire assessing 5 key characteristics on a scale from 1 to 5. The prompts were categorized into 3 areas: diagnosis and preoperative management, surgical timing and technique, and rehabilitation and prevention. Statistical analysis included mean scoring, standard deviation, and 2-sided t tests to compare the performance between the 2 large language models (LLMs). Scores were then evaluated for inter-rater reliability (IRR).
Results
Overall, both LLMs performed well with mean scores >4 for the 5 key characteristics. Gemini demonstrated superior performance in overall clarity (4.848 ± 0.36 vs 4.743 ± 0.481, P = .034), but all other characteristics demonstrated nonsignificant differences (P > .05). Gemini also demonstrated superior clarity in the surgical timing and technique (P = .038) as well as the prevention and rehabilitation (P = .044) subcategories. Additionally, Gemini had superior performance completeness scores in the rehabilitation and prevention subcategory (P = .044), but no statistically significant differences were found amongst the other subcategories. The overall IRR was found to be 0.71 (moderate).
Conclusions
Both Gemini and ChatGPT-4 demonstrate an overall good ability to generate accurate and relevant responses to question prompts based on the 2022 AAOS CPG for ACLR. However, Gemini demonstrated superior clarity in multiple domains in addition to superior completeness for questions pertaining to rehabilitation and prevention.
Clinical Relevance
The current study addresses a current gap in the LLM and ACLR literature by comparing the performance of ChatGPT-4 to Gemini, which is growing in popularity with more than 300 million individual uses in May 2024 alone. Moreover, the results demonstrated superior performance of Gemini in both clarity and completeness, which are critical elements of a tool being used by patients for educational purposes. Additionally, the current study uses question prompts based on the AAOS CPG, which may be used as a method of standardization for future investigations on performance of LLM platforms. Thus, the results of this study may be of interest to both the readership of Arthroscopy and patients.
ER  - 

TY  - JOUR
T1  - Rationalism in the face of GPT hypes: Benchmarking the output of large language models against human expert-curated biomedical knowledge graphs
AU  - Babaiha, Negin Sadat
AU  - Rao, Sathvik Guru
AU  - Klein, Jürgen
AU  - Schultz, Bruce
AU  - Jacobs, Marc
AU  - Hofmann-Apitius, Martin
JO  - Artificial Intelligence in the Life Sciences
VL  - 5
SP  - 100095
PY  - 2024
DA  - 2024/06/01/
SN  - 2667-3185
DO  - https://doi.org/10.1016/j.ailsci.2024.100095
UR  - https://www.sciencedirect.com/science/article/pii/S2667318524000023
KW  - Large language models (LLMs)
KW  - Natural language processing (NLP)
KW  - Biomedical text mining
KW  - Biomedical knowledge graphs
KW  - Biological expression language (BEL)
AB  - Biomedical knowledge graphs (KGs) hold valuable information regarding biomedical entities such as genes, diseases, biological processes, and drugs. KGs have been successfully employed in challenging biomedical areas such as the identification of pathophysiology mechanisms or drug repurposing. The creation of high-quality KGs typically requires labor-intensive multi-database integration or substantial human expert curation, both of which take time and contribute to the workload of data processing and annotation. Therefore, the use of automatic systems for KG building and maintenance is a prerequisite for the wide uptake and utilization of KGs. Technologies supporting the automated generation and updating of KGs typically make use of Natural Language Processing (NLP), which is optimized for extracting implicit triples described in relevant biomedical text sources. At the core of this challenge is how to improve the accuracy and coverage of the information extraction module by utilizing different models and tools. The emergence of pre-trained large language models (LLMs), such as ChatGPT which has grown in popularity dramatically, has revolutionized the field of NLP, making them a potential candidate to be used in text-based graph creation as well. So far, no previous work has investigated the power of LLMs on the generation of cause-and-effect networks and KGs encoded in Biological Expression Language (BEL). In this paper, we present initial studies towards one-shot BEL relation extraction using two different versions of the Generative Pre-trained Transformer (GPT) models and evaluate its performance by comparing the extracted results to a highly accurate, manually curated BEL KG curated by domain experts.
ER  - 

TY  - JOUR
T1  - Generative Artificial Intelligence Through ChatGPT and Other Large Language Models in Ophthalmology: Clinical Applications and Challenges
AU  - Tan, Ting Fang
AU  - Thirunavukarasu, Arun James
AU  - Campbell, J. Peter
AU  - Keane, Pearse A.
AU  - Pasquale, Louis R.
AU  - Abramoff, Michael D.
AU  - Kalpathy-Cramer, Jayashree
AU  - Lum, Flora
AU  - Kim, Judy E.
AU  - Baxter, Sally L.
AU  - Ting, Daniel Shu Wei
JO  - Ophthalmology Science
VL  - 3
IS  - 4
SP  - 100394
PY  - 2023
DA  - 2023/12/01/
SN  - 2666-9145
DO  - https://doi.org/10.1016/j.xops.2023.100394
UR  - https://www.sciencedirect.com/science/article/pii/S2666914523001264
KW  - Artificial intelligence
KW  - Chatbots
KW  - ChatGPT
KW  - Large language models
AB  - The rapid progress of large language models (LLMs) driving generative artificial intelligence applications heralds the potential of opportunities in health care. We conducted a review up to April 2023 on Google Scholar, Embase, MEDLINE, and Scopus using the following terms: “large language models,” “generative artificial intelligence,” “ophthalmology,” “ChatGPT,” and “eye,” based on relevance to this review. From a clinical viewpoint specific to ophthalmologists, we explore from the different stakeholders’ perspectives—including patients, physicians, and policymakers—the potential LLM applications in education, research, and clinical domains specific to ophthalmology. We also highlight the foreseeable challenges of LLM implementation into clinical practice, including the concerns of accuracy, interpretability, perpetuating bias, and data security. As LLMs continue to mature, it is essential for stakeholders to jointly establish standards for best practices to safeguard patient safety.
Financial Disclosure(s)
Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.
ER  - 

TY  - JOUR
T1  - DeBERTa-GRU: Sentiment Analysis for Large Language Model
AU  - Assiri, Adel
AU  - Gumaei, Abdu
AU  - Mehmood, Faisal
AU  - Abbas, Touqeer
AU  - Ullah, Sami
JO  - Computers, Materials and Continua
VL  - 79
IS  - 3
SP  - 4219
EP  - 4236
PY  - 2024
DA  - 2024/06/20/
SN  - 1546-2218
DO  - https://doi.org/10.32604/cmc.2024.050781
UR  - https://www.sciencedirect.com/science/article/pii/S1546221824000183
KW  - DeBERTa
KW  - GRU
KW  - Naive Bayes
KW  - LSTM
KW  - sentiment analysis
KW  - large language model
AB  - Modern technological advancements have made social media an essential component of daily life. Social media allow individuals to share thoughts, emotions, and ideas. Sentiment analysis plays the function of evaluating whether the sentiment of the text is positive, negative, neutral, or any other personal emotion to understand the sentiment context of the text. Sentiment analysis is essential in business and society because it impacts strategic decision-making. Sentiment analysis involves challenges due to lexical variation, an unlabeled dataset, and text distance correlations. The execution time increases due to the sequential processing of the sequence models. However, the calculation times for the Transformer models are reduced because of the parallel processing. This study uses a hybrid deep learning strategy to combine the strengths of the Transformer and Sequence models while ignoring their limitations. In particular, the proposed model integrates the Decoding-enhanced with Bidirectional Encoder Representations from Transformers (BERT) attention (DeBERTa) and the Gated Recurrent Unit (GRU) for sentiment analysis. Using the Decoding-enhanced BERT technique, the words are mapped into a compact, semantic word embedding space, and the Gated Recurrent Unit model can capture the distance contextual semantics correctly. The proposed hybrid model achieves F1-scores of 97% on the Twitter Large Language Model (LLM) dataset, which is much higher than the performance of new techniques.
ER  - 

TY  - JOUR
T1  - A novel large language model enhanced joint learning framework for fine-grained sentiment analysis on drug reviews
AU  - Zou, Haochen
AU  - Wang, Yongli
JO  - Neurocomputing
SP  - 129589
PY  - 2025
DA  - 2025/02/04/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2025.129589
UR  - https://www.sciencedirect.com/science/article/pii/S0925231225002619
KW  - Fine-grained sentiment analysis
KW  - Aspect-based sentiment analysis
KW  - Large language model
KW  - Health informatics
AB  - Patient feedback on drug reviews extracted from social media platforms and online forums provides genuine sentiment information regarding post-medication usage. The insights are invaluable for prospective patients seeking appropriate medical guidance and stakeholders within the biomedical industry aiming to improve products. This paper presents a novel joint learning framework for fine-grained aspect-based sentiment analysis on drug reviews. By leveraging prior biomedical knowledge from the domain-specific pre-trained large language model, we address the challenge of fine-grained aspect-based sentiment analysis by collaboratively integrating both coarse and fine-grained contextual features within the text content, capturing precise biomedical aspect terms and the corresponding sentiment polarities. To the best of our knowledge, this work pioneers the initial introduction of a joint learning framework based on the fine-tuned biomedical large language model for fine-grained aspect-based sentiment analysis within drug reviews. By conducting extensive experiments on publicly available drug review datasets and comparing the constructed architecture with state-of-the-art techniques, the joint learning framework outperforms baseline competitors across evaluation metrics.
ER  - 

TY  - JOUR
T1  - Mastering building management systems data points tagging with minimal examples: unveiling the power of large language models
AU  - Zheng, Zhiyu
AU  - Marié, Sylvain
AU  - Farazdaghi, Elham
AU  - Yahia, Esma
AU  - Makhoul, Khal
AU  - Lagarde, Théo
AU  - Meouche, Rani El
AU  - Ababsa, Fakhreddine
JO  - Energy and Buildings
VL  - 328
SP  - 115173
PY  - 2025
DA  - 2025/02/01/
SN  - 0378-7788
DO  - https://doi.org/10.1016/j.enbuild.2024.115173
UR  - https://www.sciencedirect.com/science/article/pii/S0378778824012891
KW  - Large Language Models
KW  - Building Management Systems
KW  - Brick Ontology
KW  - Semantic Web Technologies
KW  - Metadata Tagging
KW  - Few-Shot Learning, Prompt Engineering
AB  - The heterogeneity of metadata within Building Management Systems (BMS) poses substantial challenges for advanced analytics, including cross-building analysis. Over the past decade, metadata standard schemas such as Brick have been developed to address this challenge. Nevertheless, mapping BMS metadata with such standards accurately and efficiently continues to be a demanding task across both new and existing buildings. This work explores the application of Large Language Models (LLMs) to tag BMS data points, thus facilitating metadata standardization efforts. Manual or rule-based methods are not only labor-intensive but also error-prone. Similarly, supervised learning approaches using Machine Learning (ML) and Natural Language Processing (NLP) demand extensive labeled datasets, often making them laborious and inflexible to new BMS metadata types and tasks. We propose a novel three-step framework that enhances the tagging process by integrating a LLM with few-shot prompting and an embedding model. This approach not only improves result interpretability but also effectively mitigates hallucinations. This framework is further supported by analyses of the LLM’s inherent capabilities, prompt-aided specific interpretation and output formatting, and evaluations of few-shot sizes. Tested across five different building datasets, our approach, leveraging few-shot examples, achieves performance comparable to state-of-the-art supervised learning methods that rely on large labeled datasets.
ER  - 

TY  - JOUR
T1  - Low-resource knowledge graph completion based on knowledge distillation driven by large language models
AU  - Hou, Wenlong
AU  - Zhao, Weidong
AU  - Jia, Ning
AU  - Liu, Xianhui
JO  - Applied Soft Computing
VL  - 169
SP  - 112622
PY  - 2025
DA  - 2025/01/01/
SN  - 1568-4946
DO  - https://doi.org/10.1016/j.asoc.2024.112622
UR  - https://www.sciencedirect.com/science/article/pii/S1568494624013966
KW  - Knowledge graph completion
KW  - Knowledge reasoning
KW  - Link prediction
KW  - Large language models
AB  - Knowledge graph completion (KGC) refines the existing knowledge graph (KG) by predicting missing entities or relations. Existing methods are mainly based on embeddings or texts but only perform better with abundant labeled data. Hence, KGC in resource-constrained settings is a significant problem, which faces challenges of data imbalance across relations and lack of relation label semantics. Considering that Large Language Models (LLMs) demonstrate powerful reasoning and generation capabilities, this work proposes an LLM-driven Knowledge Graph Completion Distillation (KGCD) model to address low-resource KGC. A two-stage framework is developed, involving teacher-student distillation by using LLM to improve reasoning, followed by fine-tuning on real-world low-resource datasets. To deal with data imbalance, a hybrid prompt design for LLM is proposed, which includes rethink and open prompts. Furthermore, a virtual relation label generation strategy enhances the model’s understanding of triples. Extensive experiments on three benchmarks have shown that KGCD’s effectiveness for low-resource KGC, achieving improvements in Mean Reciprocal Rank (MRR) by 11% and Hits@1 by 10% on the WN18, MRR by 10% and Hits@1 by 14% on the WN18RR, and MRR by 12% and Hits@1 by 11% on the YAGO3-10.
ER  - 

TY  - JOUR
T1  - Beyond semantic distance: Automated scoring of divergent thinking greatly improves with large language models
AU  - Organisciak, Peter
AU  - Acar, Selcuk
AU  - Dumas, Denis
AU  - Berthiaume, Kelly
JO  - Thinking Skills and Creativity
VL  - 49
SP  - 101356
PY  - 2023
DA  - 2023/09/01/
SN  - 1871-1871
DO  - https://doi.org/10.1016/j.tsc.2023.101356
UR  - https://www.sciencedirect.com/science/article/pii/S1871187123001256
KW  - Divergent thinking
KW  - Alternate uses test
KW  - Large-language models
KW  - Automated scoring
AB  - Automated scoring for divergent thinking (DT) seeks to overcome a key obstacle to creativity measurement: the effort, cost, and reliability of scoring open-ended tests. For a common test of DT, the Alternate Uses Task (AUT), the primary automated approach casts the problem as a semantic distance between a prompt and the resulting idea in a text model. This work presents an alternative approach that greatly surpasses the performance of the best existing semantic distance approaches. Our system, Ocsai, fine-tunes deep neural network-based large-language models (LLMs) on human-judged responses. Trained and evaluated against one of the largest collections of human-judged AUT responses, with 27 thousand responses collected from nine past studies, our fine-tuned large-language-models achieved up to r = 0.81 correlation with human raters, greatly surpassing current systems (r = 0.12–0.26). Further, learning transfers well to new test items and the approach is still robust with small numbers of training labels. We also compare prompt-based zero-shot and few-shot approaches, using GPT-3, ChatGPT, and GPT-4. This work also suggests a limit to the underlying assumptions of the semantic distance model, showing that a purely semantic approach that uses the stronger language representation of LLMs, while still improving on existing systems, does not achieve comparable improvements to our fine-tuned system. The increase in performance can support stronger applications and interventions in DT and opens the space of automated DT scoring to new areas for improving and understanding this branch of methods.
ER  - 

TY  - JOUR
T1  - A Comparative Study of Responses to Retina Questions from Either Experts, Expert-Edited Large Language Models, or Expert-Edited Large Language Models Alone
AU  - Tailor, Prashant D.
AU  - Dalvin, Lauren A.
AU  - Chen, John J.
AU  - Iezzi, Raymond
AU  - Olsen, Timothy W.
AU  - Scruggs, Brittni A.
AU  - Barkmeier, Andrew J.
AU  - Bakri, Sophie J.
AU  - Ryan, Edwin H.
AU  - Tang, Peter H.
AU  - Parke, D. Wilkin.
AU  - Belin, Peter J.
AU  - Sridhar, Jayanth
AU  - Xu, David
AU  - Kuriyan, Ajay E.
AU  - Yonekawa, Yoshihiro
AU  - Starr, Matthew R.
JO  - Ophthalmology Science
VL  - 4
IS  - 4
SP  - 100485
PY  - 2024
DA  - 2024/07/01/
SN  - 2666-9145
DO  - https://doi.org/10.1016/j.xops.2024.100485
UR  - https://www.sciencedirect.com/science/article/pii/S2666914524000216
KW  - Artificial intelligence
KW  - Chatbot
KW  - ChatGPT
KW  - Large language model
KW  - Retina
AB  - Objective
To assess the quality, empathy, and safety of expert edited large language model (LLM), human expert created, and LLM responses to common retina patient questions.
Design
Randomized, masked multicenter study.
Participants
Twenty-one common retina patient questions were randomly assigned among 13 retina specialists.
Methods
Each expert created a response (Expert) and then edited a LLM (ChatGPT-4)-generated response to that question (Expert + artificial intelligence [AI]), timing themselves for both tasks. Five LLMs (ChatGPT-3.5, ChatGPT-4, Claude 2, Bing, and Bard) also generated responses to each question. The original question along with anonymized and randomized Expert + AI, Expert, and LLM responses were evaluated by the other experts who did not write an expert response to the question. Evaluators judged quality and empathy (very poor, poor, acceptable, good, or very good) along with safety metrics (incorrect information, likelihood to cause harm, extent of harm, and missing content).
Main Outcome
Mean quality and empathy score, proportion of responses with incorrect information, likelihood to cause harm, extent of harm, and missing content for each response type.
Results
There were 4008 total grades collected (2608 for quality and empathy; 1400 for safety metrics), with significant differences in both quality and empathy (P < 0.001, P < 0.001) between LLM, Expert and Expert + AI groups. For quality, Expert + AI (3.86 ± 0.85) performed the best overall while GPT-3.5 (3.75 ± 0.79) was the top performing LLM. For empathy, GPT-3.5 (3.75 ± 0.69) had the highest mean score followed by Expert + AI (3.73 ± 0.63). By mean score, Expert placed 4 out of 7 for quality and 6 out of 7 for empathy. For both quality (P < 0.001) and empathy (P < 0.001), expert-edited LLM responses performed better than expert-created responses. There were time savings for an expert-edited LLM response versus expert-created response (P = 0.02). ChatGPT-4 performed similar to Expert for inappropriate content (P = 0.35), missing content (P = 0.001), extent of possible harm (P = 0.356), and likelihood of possible harm (P = 0.129).
Conclusions
In this randomized, masked, multicenter study, LLM responses were comparable with experts in terms of quality, empathy, and safety metrics, warranting further exploration of their potential benefits in clinical settings.
Financial Disclosure(s)
Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of the article.
ER  - 

TY  - JOUR
T1  - Large Language Models in Gastroenterology: Systematic Review
AU  - Gong, Eun Jeong
AU  - Bang, Chang Seok
AU  - Lee, Jae Jun
AU  - Park, Jonghyung
AU  - Kim, Eunsil
AU  - Kim, Subeen
AU  - Kimm, Minjae
AU  - Choi, Seoung-Ho
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/66648
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124009907
KW  - large language model
KW  - LLM
KW  - deep learning
KW  - artificial intelligence
KW  - AI
KW  - endoscopy
KW  - gastroenterology
KW  - clinical practice
KW  - systematic review
KW  - diagnostic
KW  - accuracy
KW  - patient engagement
KW  - emotional support
KW  - data privacy
KW  - diagnosis
KW  - clinical reasoning
AB  - Background
As health care continues to evolve with technological advancements, the integration of artificial intelligence into clinical practices has shown promising potential to enhance patient care and operational efficiency. Among the forefront of these innovations are large language models (LLMs), a subset of artificial intelligence designed to understand, generate, and interact with human language at an unprecedented scale.
Objective
This systematic review describes the role of LLMs in improving diagnostic accuracy, automating documentation, and advancing specialist education and patient engagement within the field of gastroenterology and gastrointestinal endoscopy.
Methods
Core databases including MEDLINE through PubMed, Embase, and Cochrane Central registry were searched using keywords related to LLMs (from inception to April 2024). Studies were included if they satisfied the following criteria: (1) any type of studies that investigated the potential role of LLMs in the field of gastrointestinal endoscopy or gastroenterology, (2) studies published in English, and (3) studies in full-text format. The exclusion criteria were as follows: (1) studies that did not report the potential role of LLMs in the field of gastrointestinal endoscopy or gastroenterology, (2) case reports and review papers, (3) ineligible research objects (eg, animals or basic research), and (4) insufficient data regarding the potential role of LLMs. Risk of Bias in Non-Randomized Studies—of Interventions was used to evaluate the quality of the identified studies.
Results
Overall, 21 studies on the potential role of LLMs in gastrointestinal disorders were included in the systematic review, and narrative synthesis was done because of heterogeneity in the specified aims and methodology in each included study. The overall risk of bias was low in 5 studies and moderate in 16 studies. The ability of LLMs to spread general medical information, offer advice for consultations, generate procedure reports automatically, or draw conclusions about the presumptive diagnosis of complex medical illnesses was demonstrated by the systematic review. Despite promising benefits, such as increased efficiency and improved patient outcomes, challenges related to data privacy, accuracy, and interdisciplinary collaboration remain.
Conclusions
We highlight the importance of navigating these challenges to fully leverage LLMs in transforming gastrointestinal endoscopy practices.
Trial Registration
PROSPERO 581772; https://www.crd.york.ac.uk/prospero/
ER  - 

TY  - JOUR
T1  - Accuracy of Large Language Models for Infective Endocarditis Prophylaxis in Dental Procedures
AU  - Rewthamrongsris, Paak
AU  - Burapacheep, Jirayu
AU  - Trachoo, Vorapat
AU  - Porntaveetus, Thantrira
JO  - International Dental Journal
VL  - 75
IS  - 1
SP  - 206
EP  - 212
PY  - 2025
DA  - 2025/02/01/
SN  - 0020-6539
DO  - https://doi.org/10.1016/j.identj.2024.09.033
UR  - https://www.sciencedirect.com/science/article/pii/S0020653924015466
KW  - Artificial intelligence
KW  - ChatGPT
KW  - AHA guidelines
KW  - Gemini
KW  - Claude
AB  - Purpose
Infective endocarditis (IE) is a serious, life-threatening condition requiring antibiotic prophylaxis for high-risk individuals undergoing invasive dental procedures. As LLMs are rapidly adopted by dental professionals for their efficiency and accessibility, assessing their accuracy in answering critical questions about antibiotic prophylaxis for IE prevention is crucial.
Methods
Twenty-eight true/false questions based on the 2021 American Heart Association (AHA) guidelines for IE were posed to 7 popular LLMs. Each model underwent five independent runs per question using two prompt strategies: a pre-prompt as an experienced dentist and without a pre-prompt. Inter-model comparisons utilised the Kruskal–Wallis test, followed by post-hoc pairwise comparisons using Prism 10 software.
Results
Significant differences in accuracy were observed among the LLMs. All LLMs had a narrower confidence interval with a pre-prompt, and most, except Claude 3 Opus, showed improved performance. GPT-4o had the highest accuracy (80% with a pre-prompt, 78.57% without), followed by Gemini 1.5 Pro (78.57% and 77.86%) and Claude 3 Opus (75.71% and 77.14%). Gemini 1.5 Flash had the lowest accuracy (68.57% and 63.57%). Without a pre-prompt, Gemini 1.5 Flash's accuracy was significantly lower than Claude 3 Opus, Gemini 1.5 Pro, and GPT-4o. With a pre-prompt, Gemini 1.5 Flash and Claude 3.5 were significantly less accurate than Gemini 1.5 Pro and GPT-4o. None of the LLMs met the commonly used benchmark scores. All models provided both correct and incorrect answers randomly, except Claude 3.5 Sonnet with a pre-prompt, which consistently gave incorrect answers to eight questions across five runs.
Conclusion
LLMs like GPT-4o show promise for retrieving AHA-IE guideline information, achieving up to 80% accuracy. However, complex medical questions may still pose a challenge. Pre-prompts offer a potential solution, and domain-specific training is essential for optimizing LLM performance in healthcare, especially with the emergence of models with increased token limits.
ER  - 

TY  - JOUR
T1  - Dissociating language and thought in large language models
AU  - Mahowald, Kyle
AU  - Ivanova, Anna A.
AU  - Blank, Idan A.
AU  - Kanwisher, Nancy
AU  - Tenenbaum, Joshua B.
AU  - Fedorenko, Evelina
JO  - Trends in Cognitive Sciences
VL  - 28
IS  - 6
SP  - 517
EP  - 540
PY  - 2024
DA  - 2024/06/01/
SN  - 1364-6613
DO  - https://doi.org/10.1016/j.tics.2024.01.011
UR  - https://www.sciencedirect.com/science/article/pii/S1364661324000275
KW  - large language models
KW  - language and thought
KW  - cognitive neuroscience
KW  - linguistic competence
KW  - computational modeling
AB  - Large language models (LLMs) have come closest among all models to date to mastering human language, yet opinions about their linguistic and cognitive capabilities remain split. Here, we evaluate LLMs using a distinction between formal linguistic competence (knowledge of linguistic rules and patterns) and functional linguistic competence (understanding and using language in the world). We ground this distinction in human neuroscience, which has shown that formal and functional competence rely on different neural mechanisms. Although LLMs are surprisingly good at formal competence, their performance on functional competence tasks remains spotty and often requires specialized fine-tuning and/or coupling with external modules. We posit that models that use language in human-like ways would need to master both of these competence types, which, in turn, could require the emergence of separate mechanisms specialized for formal versus functional linguistic competence.
ER  - 

TY  - JOUR
T1  - Large Language Models Can Enable Inductive Thematic Analysis of a Social Media Corpus in a Single Prompt: Human Validation Study
AU  - Deiner, Michael S
AU  - Honcharov, Vlad
AU  - Li, Jiawei
AU  - Mackey, Tim K
AU  - Porco, Travis C
AU  - Sarkar, Urmimala
JO  - JMIR Infodemiology
VL  - 4
PY  - 2024
DA  - 2024/01/01/
SN  - 2564-1891
DO  - https://doi.org/10.2196/59641
UR  - https://www.sciencedirect.com/science/article/pii/S2564189124000185
KW  - generative large language model
KW  - generative pretrained transformer
KW  - GPT
KW  - Claude
KW  - Twitter
KW  - X formerly known as Twitter
KW  - social media
KW  - inductive content analysis
KW  - COVID-19
KW  - vaccine hesitancy
KW  - infodemiology
AB  - Background
Manually analyzing public health–related content from social media provides valuable insights into the beliefs, attitudes, and behaviors of individuals, shedding light on trends and patterns that can inform public understanding, policy decisions, targeted interventions, and communication strategies. Unfortunately, the time and effort needed from well-trained human subject matter experts makes extensive manual social media listening unfeasible. Generative large language models (LLMs) can potentially summarize and interpret large amounts of text, but it is unclear to what extent LLMs can glean subtle health-related meanings in large sets of social media posts and reasonably report health-related themes.
Objective
We aimed to assess the feasibility of using LLMs for topic model selection or inductive thematic analysis of large contents of social media posts by attempting to answer the following question: Can LLMs conduct topic model selection and inductive thematic analysis as effectively as humans did in a prior manual study, or at least reasonably, as judged by subject matter experts?
Methods
We asked the same research question and used the same set of social media content for both the LLM selection of relevant topics and the LLM analysis of themes as was conducted manually in a published study about vaccine rhetoric. We used the results from that study as background for this LLM experiment by comparing the results from the prior manual human analyses with the analyses from 3 LLMs: GPT4-32K, Claude-instant-100K, and Claude-2-100K. We also assessed if multiple LLMs had equivalent ability and assessed the consistency of repeated analysis from each LLM.
Results
The LLMs generally gave high rankings to the topics chosen previously by humans as most relevant. We reject a null hypothesis (P<.001, overall comparison) and conclude that these LLMs are more likely to include the human-rated top 5 content areas in their top rankings than would occur by chance. Regarding theme identification, LLMs identified several themes similar to those identified by humans, with very low hallucination rates. Variability occurred between LLMs and between test runs of an individual LLM. Despite not consistently matching the human-generated themes, subject matter experts found themes generated by the LLMs were still reasonable and relevant.
Conclusions
LLMs can effectively and efficiently process large social media–based health-related data sets. LLMs can extract themes from such data that human subject matter experts deem reasonable. However, we were unable to show that the LLMs we tested can replicate the depth of analysis from human subject matter experts by consistently extracting the same themes from the same data. There is vast potential, once better validated, for automated LLM-based real-time social listening for common and rare health conditions, informing public health understanding of the public’s interests and concerns and determining the public’s ideas to address them.
ER  - 

TY  - JOUR
T1  - Practical Applications of Large Language Models for Health Care Professionals and Scientists
AU  - Reis, Florian
AU  - Lenz, Christian
AU  - Gossen, Manfred
AU  - Volk, Hans-Dieter
AU  - Drzeniek, Norman Michael
JO  - JMIR Medical Informatics
VL  - 12
PY  - 2024
DA  - 2024/01/01/
SN  - 2291-9694
DO  - https://doi.org/10.2196/58478
UR  - https://www.sciencedirect.com/science/article/pii/S2291969424001145
KW  - artificial intelligence
KW  - healthcare
KW  - chatGPT
KW  - large language model
KW  - prompting
KW  - LLM
KW  - applications
KW  - AI
KW  - scientists
KW  - physicians
KW  - health care
AB  - With the popularization of large language models (LLMs), strategies for their effective and safe usage in health care and research have become increasingly pertinent. Despite the growing interest and eagerness among health care professionals and scientists to exploit the potential of LLMs, initial attempts may yield suboptimal results due to a lack of user experience, thus complicating the integration of artificial intelligence (AI) tools into workplace routine. Focusing on scientists and health care professionals with limited LLM experience, this viewpoint article highlights and discusses 6 easy-to-implement use cases of practical relevance. These encompass customizing translations, refining text and extracting information, generating comprehensive overviews and specialized insights, compiling ideas into cohesive narratives, crafting personalized educational materials, and facilitating intellectual sparring. Additionally, we discuss general prompting strategies and precautions for the implementation of AI tools in biomedicine. Despite various hurdles and challenges, the integration of LLMs into daily routines of physicians and researchers promises heightened workplace productivity and efficiency.
ER  - 

TY  - JOUR
T1  - Extracting chemical food safety hazards from the scientific literature automatically using large language models
AU  - Özen, Neris
AU  - Mu, Wenjuan
AU  - van Asselt, Esther D.
AU  - van den Bulk, Leonieke M.
JO  - Applied Food Research
VL  - 5
IS  - 1
SP  - 100679
PY  - 2025
DA  - 2025/06/01/
SN  - 2772-5022
DO  - https://doi.org/10.1016/j.afres.2024.100679
UR  - https://www.sciencedirect.com/science/article/pii/S2772502224002890
KW  - Chemical contamination
KW  - Food safety
KW  - Information extraction
KW  - Prompt engineering
KW  - Natural language processing
KW  - Artificial intelligence
AB  - The number of scientific articles published in the domain of food safety has consistently been increasing over the last few decades. It has therefore become unfeasible for food safety experts to read all relevant literature related to food safety and the occurrence of hazards in the food chain. However, it is important that food safety experts are aware of the newest findings and can access this information in an easy and concise way. In this study, an approach is presented to automate the extraction of chemical hazards from the scientific literature through large language models. The large language model was used out-of-the-box and applied on scientific abstracts; no extra training of the models or a large computing cluster was required. Three different styles of prompting the model were tested to assess which was the most optimal for the task at hand. The prompts were optimized with two validation foods (leafy greens and shellfish) and the final performance of the best prompt was evaluated using three test foods (dairy, maize and salmon). The specific wording of the prompt was found to have a considerable effect on the results. A prompt breaking the task down into smaller steps performed best overall. This prompt reached an average accuracy of 93 % and contained many chemical contaminants already included in food monitoring programs, validating the successful retrieval of relevant hazards for the food safety domain. The results showcase how valuable large language models can be for the task of automatic information extraction from the scientific literature.
ER  - 

TY  - JOUR
T1  - Accuracy of a Proprietary Large Language Model in Labeling Obstetric Incident Reports
AU  - Johnson, Jeanene
AU  - Brown, Conner
AU  - Lee, Grace
AU  - Morse, Keith
JO  - The Joint Commission Journal on Quality and Patient Safety
VL  - 50
IS  - 12
SP  - 877
EP  - 881
PY  - 2024
DA  - 2024/12/01/
SN  - 1553-7250
DO  - https://doi.org/10.1016/j.jcjq.2024.08.001
UR  - https://www.sciencedirect.com/science/article/pii/S1553725024002332
AB  - Background
Using the data collected through incident reporting systems is challenging, as it is a large volume of primarily qualitative information. Large language models (LLMs), such as ChatGPT, provide novel capabilities in text summarization and labeling that could support safety data trending and early identification of opportunities to prevent patient harm. This study assessed the capability of a proprietary LLM (GPT-3.5) to automatically label a cross-sectional sample of real-world obstetric incident reports.
Methods
A sample of 370 incident reports submitted to inpatient obstetric units between December 2022 and May 2023 was extracted. Human-annotated labels were assigned by a clinician reviewer and considered gold standard. The LLM was prompted to label incident reports relying solely on its pretrained knowledge and information included in the prompt. Primary outcomes assessed were sensitivity, specificity, positive predictive value, and negative predictive value. A secondary outcome assessed the human-perceived quality of the model's justification for the label(s) applied.
Results
The LLM demonstrated the ability to label incident reports with high sensitivity and specificity. The model applied a total of 79 labels compared to the reviewer's 49 labels. Overall sensitivity for the model was 85.7%, and specificity was 97.9%. Positive and negative predictive values were 53.2% and 99.6%, respectively. For 60.8% of labels, the reviewer approved of the model's justification for applying the label.
Conclusion
The proprietary LLM demonstrated the ability to label obstetric incident reports with high sensitivity and specificity. LLMs offer the potential to enable more efficient use of data from incident reporting systems.
ER  - 

TY  - JOUR
T1  - PneumoLLM: Harnessing the power of large language model for pneumoconiosis diagnosis
AU  - Song, Meiyue
AU  - Wang, Jiarui
AU  - Yu, Zhihua
AU  - Wang, Jiaxin
AU  - Yang, Le
AU  - Lu, Yuting
AU  - Li, Baicun
AU  - Wang, Xue
AU  - Wang, Xiaoxu
AU  - Huang, Qinghua
AU  - Li, Zhijun
AU  - Kanellakis, Nikolaos I.
AU  - Liu, Jiangfeng
AU  - Wang, Jing
AU  - Wang, Binglu
AU  - Yang, Juntao
JO  - Medical Image Analysis
VL  - 97
SP  - 103248
PY  - 2024
DA  - 2024/10/01/
SN  - 1361-8415
DO  - https://doi.org/10.1016/j.media.2024.103248
UR  - https://www.sciencedirect.com/science/article/pii/S1361841524001737
KW  - Large language model
KW  - Medical image diagnosis
KW  - Foundational model
AB  - The conventional pretraining-and-finetuning paradigm, while effective for common diseases with ample data, faces challenges in diagnosing data-scarce occupational diseases like pneumoconiosis. Recently, large language models (LLMs) have exhibits unprecedented ability when conducting multiple tasks in dialogue, bringing opportunities to diagnosis. A common strategy might involve using adapter layers for vision–language alignment and diagnosis in a dialogic manner. Yet, this approach often requires optimization of extensive learnable parameters in the text branch and the dialogue head, potentially diminishing the LLMs’ efficacy, especially with limited training data. In our work, we innovate by eliminating the text branch and substituting the dialogue head with a classification head. This approach presents a more effective method for harnessing LLMs in diagnosis with fewer learnable parameters. Furthermore, to balance the retention of detailed image information with progression towards accurate diagnosis, we introduce the contextual multi-token engine. This engine is specialized in adaptively generating diagnostic tokens. Additionally, we propose the information emitter module, which unidirectionally emits information from image tokens to diagnosis tokens. Comprehensive experiments validate the superiority of our methods.
ER  - 

TY  - JOUR
T1  - The Opportunities and Risks of Large Language Models in Mental Health
AU  - Lawrence, Hannah R
AU  - Schneider, Renee A
AU  - Rubin, Susan B
AU  - Matarić, Maja J
AU  - McDuff, Daniel J
AU  - Jones Bell, Megan
JO  - JMIR Mental Health
VL  - 11
PY  - 2024
DA  - 2024/01/01/
SN  - 2368-7959
DO  - https://doi.org/10.2196/59479
UR  - https://www.sciencedirect.com/science/article/pii/S2368795924000799
KW  - artificial intelligence
KW  - AI
KW  - generative AI
KW  - large language models
KW  - mental health
KW  - mental health education
KW  - language model
KW  - mental health care
KW  - health equity
KW  - ethical
KW  - development
KW  - deployment
AB  - Global rates of mental health concerns are rising, and there is increasing realization that existing models of mental health care will not adequately expand to meet the demand. With the emergence of large language models (LLMs) has come great optimism regarding their promise to create novel, large-scale solutions to support mental health. Despite their nascence, LLMs have already been applied to mental health–related tasks. In this paper, we summarize the extant literature on efforts to use LLMs to provide mental health education, assessment, and intervention and highlight key opportunities for positive impact in each area. We then highlight risks associated with LLMs’ application to mental health and encourage the adoption of strategies to mitigate these risks. The urgent need for mental health support must be balanced with responsible development, testing, and deployment of mental health LLMs. It is especially critical to ensure that mental health LLMs are fine-tuned for mental health, enhance mental health equity, and adhere to ethical standards and that people, including those with lived experience with mental health concerns, are involved in all stages from development through deployment. Prioritizing these efforts will minimize potential harms to mental health and maximize the likelihood that LLMs will positively impact mental health globally.
ER  - 

TY  - JOUR
T1  - Model tuning or prompt Tuning? a study of large language models for clinical concept and relation extraction
AU  - Peng, Cheng
AU  - Yang, Xi
AU  - Smith, Kaleb E
AU  - Yu, Zehao
AU  - Chen, Aokun
AU  - Bian, Jiang
AU  - Wu, Yonghui
JO  - Journal of Biomedical Informatics
VL  - 153
SP  - 104630
PY  - 2024
DA  - 2024/05/01/
SN  - 1532-0464
DO  - https://doi.org/10.1016/j.jbi.2024.104630
UR  - https://www.sciencedirect.com/science/article/pii/S1532046424000480
KW  - Prompt tuning
KW  - Large language model
KW  - Clinical concept extraction
KW  - Relation extraction
KW  - Transformer model
AB  - Objective
To develop soft prompt-based learning architecture for large language models (LLMs), examine prompt-tuning using frozen/unfrozen LLMs, and assess their abilities in transfer learning and few-shot learning.
Methods
We developed a soft prompt-based learning architecture and compared 4 strategies including (1) fine-tuning without prompts; (2) hard-prompting with unfrozen LLMs; (3) soft-prompting with unfrozen LLMs; and (4) soft-prompting with frozen LLMs. We evaluated GatorTron, a clinical LLM with up to 8.9 billion parameters, and compared GatorTron with 4 existing transformer models for clinical concept and relation extraction on 2 benchmark datasets for adverse drug events and social determinants of health (SDoH). We evaluated the few-shot learning ability and generalizability for cross-institution applications.
Results and Conclusion
When LLMs are unfrozen, GatorTron-3.9B with soft prompting achieves the best strict F1-scores of 0.9118 and 0.8604 for concept extraction, outperforming the traditional fine-tuning and hard prompt-based models by 0.6 ∼ 3.1 % and 1.2 ∼ 2.9 %, respectively; GatorTron-345 M with soft prompting achieves the best F1-scores of 0.8332 and 0.7488 for end-to-end relation extraction, outperforming other two models by 0.2 ∼ 2 % and 0.6 ∼ 11.7 %, respectively. When LLMs are frozen, small LLMs have a big gap to be competitive with unfrozen models; scaling LLMs up to billions of parameters makes frozen LLMs competitive with unfrozen models. Soft prompting with a frozen GatorTron-8.9B model achieved the best performance for cross-institution evaluation. We demonstrate that (1) machines can learn soft prompts better than hard prompts composed by human, (2) frozen LLMs have good few-shot learning ability and generalizability for cross-institution applications, (3) frozen LLMs reduce computing cost to 2.5 ∼ 6 % of previous methods using unfrozen LLMs, and (4) frozen LLMs require large models (e.g., over several billions of parameters) for good performance.
ER  - 

TY  - JOUR
T1  - Utility of conversational artificial intelligence with large language models for patient information on cardiac electrophysiology procedures
AU  - Sritharan, Hari P.
AU  - Chia, Justin
AU  - Gardiner, Kelsey
AU  - Hellestrand, Kevin
AU  - Whalley, David
AU  - Kanagaratnam, Logan
AU  - Bhindi, Ravinay
AU  - Chia, Karin K.M.
JO  - Heart Rhythm
PY  - 2024
DA  - 2024/10/09/
SN  - 1547-5271
DO  - https://doi.org/10.1016/j.hrthm.2024.10.007
UR  - https://www.sciencedirect.com/science/article/pii/S1547527124034210
KW  - Ablation
KW  - Atrial fibrillation
KW  - Artificial intelligence
KW  - Electrophysiology
KW  - Large language models
KW  - Pacemaker
KW  - Patient education
ER  - 

TY  - JOUR
T1  - Utilizing large language models in infectious disease transmission modelling for public health preparedness
AU  - Kwok, Kin On
AU  - Huynh, Tom
AU  - Wei, Wan In
AU  - Wong, Samuel Y.S.
AU  - Riley, Steven
AU  - Tang, Arthur
JO  - Computational and Structural Biotechnology Journal
VL  - 23
SP  - 3254
EP  - 3257
PY  - 2024
DA  - 2024/12/01/
SN  - 2001-0370
DO  - https://doi.org/10.1016/j.csbj.2024.08.006
UR  - https://www.sciencedirect.com/science/article/pii/S2001037024002654
KW  - Large language model
KW  - Generative artificial intelligence
KW  - Infectious diseases
KW  - Mathematical transmission modelling
KW  - Simulation and modelling
AB  - Introduction
OpenAI's ChatGPT, a Large Language Model (LLM), is a powerful tool across domains, designed for text and code generation, fostering collaboration, especially in public health. Investigating the role of this advanced LLM chatbot in assisting public health practitioners in shaping disease transmission models to inform infection control strategies, marks a new era in infectious disease epidemiology research. This study used a case study to illustrate how ChatGPT collaborates with a public health practitioner in co-designing a mathematical transmission model.
Methods
Using natural conversation, the practitioner initiated a dialogue involving an iterative process of code generation, refinement, and debugging with ChatGPT to develop a model to fit 10 days of prevalence data to estimate two key epidemiological parameters: i) basic reproductive number (Ro) and ii) final epidemic size. Verification and validation processes are conducted to ensure the accuracy and functionality of the final model.
Results
ChatGPT developed a validated transmission model which replicated the epidemic curve and gave estimates of Ro of 4.19 (95 % CI: 4.13- 4.26) and a final epidemic size of 98.3 % of the population within 60 days. It highlighted the advantages of using maximum likelihood estimation with Poisson distribution over least squares method.
Conclusion
Integration of LLM in medical research accelerates model development, reducing technical barriers for health practitioners, democratizing access to advanced modeling and potentially enhancing pandemic preparedness globally, particularly in resource-constrained populations.
ER  - 

TY  - JOUR
T1  - Enhancing or impeding? Exploring the dual impact of anthropomorphism in large language models on user aggression
AU  - Xi, Yipeng
AU  - Ji, Aitong
AU  - Yu, Weihua
JO  - Telematics and Informatics
VL  - 95
SP  - 102194
PY  - 2024
DA  - 2024/11/01/
SN  - 0736-5853
DO  - https://doi.org/10.1016/j.tele.2024.102194
UR  - https://www.sciencedirect.com/science/article/pii/S0736585324000984
KW  - Anthropomorphism
KW  - Chatbot
KW  - Dehumanization
KW  - Human nature
KW  - Human uniqueness
KW  - User aggression
AB  - This study explores the impact of anthropomorphism in large language models (LLMs) on user aggression through the lens of dehumanization theory. Specifically, it analyzes how chatbots’ human nature and human uniqueness traits influence user aggression by triggering perceived identity threats. Drawing on an online survey of 1000 LLM chatbot users in China and employing structural equation modeling, the research reveals that chatbots perceived as competent and rational tend to reduce user aggression by alleviating identity threats. In contrast, chatbots exhibiting empathetic and moral traits are more likely to heighten identity threats, thereby increasing aggression. The study further demonstrates that perceived economic value mitigates the negative impact of identity threats, while perceived emotional value exacerbates it. These findings highlight the critical need for AI designs that not only enhance user interaction but also carefully manage the potential for eliciting adverse behaviors.
ER  - 

TY  - JOUR
T1  - FEDS-ICL: Enhancing translation ability and efficiency of large language model by optimizing demonstration selection
AU  - Zhu, Shaolin
AU  - Pan, Leiyu
AU  - Xiong, Deyi
JO  - Information Processing & Management
VL  - 61
IS  - 5
SP  - 103825
PY  - 2024
DA  - 2024/09/01/
SN  - 0306-4573
DO  - https://doi.org/10.1016/j.ipm.2024.103825
UR  - https://www.sciencedirect.com/science/article/pii/S0306457324001845
KW  - Natural language processing
KW  - Large language model
KW  - Machine translation
KW  - In-context learning
AB  - Large language models (LLMs) that exhibit a remarkable ability by in-context learning (ICL) with bilingual demonstrations have been recognized as a potential solution for machine translation. However, the process of selecting these demonstrations from vast datastores is notoriously time-consuming and inefficient. Moreover, the strategies for designing effective in-context demonstrations are not well-established. To address these critical gaps, we introduce a novel Fast and Effective approach for Demonstration Selection in-Context learning (FEDS-ICL) tailored to LLMs. Our method is designed to mainly enhance the efficiency and accuracy of translation of LLMs. Our approach revolutionizes demonstration selection by designing new product quantization technique that rapidly extracts neighboring target tokens from a strategically curated subset of sentences. This method significantly deviates from the conventional exhaustive search across entire datastores, leading to a remarkable increase in speed. Furthermore, FEDS-ICL pioneers an innovative template design for in-context demonstrations, specifically crafted to amplify the translation capabilities of multilingual LLMs. In experiments, we compare our FEDS-ICL with various existing methods on across diverse language pairs on ten different LLMs. The results reveal an up to 2.1-fold increase in selection speed and an impressive enhancement in translation accuracy, outperforming existing baselines by up to 2.0 BLEU points at least on ten different LLMs. The ablation study show the proposed product quantization and multi-view demonstration can effectively enhance the efficiency and accuracy of LLMs in machine translation. The analysis on robustness of FEDS-ICL shows that the incorporation of a greater number of demonstrations can lead a positive correlation between the quantity of contextually rich demonstrations and the translation quality of LLMs. These advancements position FEDS-ICL as a transformative methodology in the domain of machine translation and pattern analysis, marking a significant leap towards more efficient and precise machine translation.
ER  - 

TY  - JOUR
T1  - Multimodal learning using large language models to improve transient identification of nuclear power plants
AU  - Qi, Ben
AU  - Sun, Jun
AU  - Sui, Zhe
AU  - Xiao, Xingyu
AU  - Liang, Jingang
JO  - Progress in Nuclear Energy
VL  - 177
SP  - 105421
PY  - 2024
DA  - 2024/12/01/
SN  - 0149-1970
DO  - https://doi.org/10.1016/j.pnucene.2024.105421
UR  - https://www.sciencedirect.com/science/article/pii/S0149197024003718
KW  - Nuclear safety
KW  - Transient identification
KW  - Multimodal learning
KW  - Large language model
KW  - Zero-shot learning
AB  - Transients are events that cause nuclear power plants (NPPs) to transition from a normal state to an abnormal state, which can lead to severe accidents if not properly handled. Transient identification is crucial for NPPs’ safety and operation. In this paper, we propose a novel multimodal text-time series learning framework(MTTL), the first work to apply a large language model for transient identification. The MTTL consists of self-supervised learning pre-training and zero-shot classification for transient identification. During pre-training, the framework utilizes a large language model(LLM) and a time-series(TS) encoder to fully exploit the rich multimodal information available in NPPs, i.e., to obtain the embeddings of both text data and TS data. The LLM is used to capture the transient knowledge of the NPPs by learning from the text data, and the TS encoder is used to capture the temporal dependencies of the transients by encoding the TS data. Both the LLM and the TS encoder have a linear projection head to map the embeddings into a common space. The similarity between the embeddings of the text and TS data is calculated to minimize the contrastive learning loss and obtain a pre-trained model with rich transient knowledge. During the zero-shot classification, the framework utilizes a pre-trained model to effectively identify real-world NPP transients where the data is different from the pre-trained simulated data. The proposed framework is evaluated on the High-Temperature Reactor-Pebblebed Modules (HTR-PM) plant, and the results demonstrate that the MTTL outperforms several baseline methods, including Transformer, LSTM, and CNN1D. The better zero-shot transient identification capability makes it possible to perform better in real-world NPPs.
ER  - 

TY  - JOUR
T1  - Enabling action crossmodality for a pretrained large language model
AU  - Caesar, Anton
AU  - Özdemir, Ozan
AU  - Weber, Cornelius
AU  - Wermter, Stefan
JO  - Natural Language Processing Journal
VL  - 7
SP  - 100072
PY  - 2024
DA  - 2024/06/01/
SN  - 2949-7191
DO  - https://doi.org/10.1016/j.nlp.2024.100072
UR  - https://www.sciencedirect.com/science/article/pii/S2949719124000207
KW  - Human–robot interaction
KW  - Machine translation
KW  - Action-vision-language model
KW  - Crossmodality
KW  - Robot learning
AB  - Natural language processing and vision tasks have recently seen large improvements through the rise of Transformer architectures. The high-performing large language models (LLMs) benefit from large textual datasets that are numerously available online. However, action and bidirectional action-language tasks are less developed, as these require more specific and labeled data. Therefore, we aim at enabling these robotic action capabilities for a pretrained LLM, while maintaining high efficiency with regards to the required training time and data size. To achieve this, we split up a Transformer-based LLM and insert a multimodal architecture into it. Specifically, we split a pretrained T5 LLM between its encoder and decoder parts, to insert a crossmodal Transformer component of a Paired Transformed Autoencoders (PTAE) bidirectional action-language model. The experiments are conducted on a new dataset, consisting of unimodal language translation and crossmodal bidirectional action-language translation. The natural language capabilities of the original T5 are re-established efficiently by training the crossmodal Transformer, which requires only one 5.7 millionth of the T5 model’s original training data. Furthermore, the new model, called CrossT5, achieves high accuracy for the vision- and language-guided robotic action tasks. By design, the CrossT5 agent acts robustly when tested with language commands not included in the dataset. The results demonstrate that this novel approach is successful in combining the advanced linguistic capabilities of LLMs with the low-level robotic control skills of vision-action models. The code is available at this URL: https://github.com/samsoneko/CrossT5.
ER  - 

TY  - JOUR
T1  - Model development for bespoke large language models for digital triage assistance in mental health care
AU  - Taylor, Niall
AU  - Kormilitzin, Andrey
AU  - Lorge, Isabelle
AU  - Nevado-Holgado, Alejo
AU  - Cipriani, Andrea
AU  - Joyce, Dan W.
JO  - Artificial Intelligence in Medicine
VL  - 157
SP  - 102988
PY  - 2024
DA  - 2024/11/01/
SN  - 0933-3657
DO  - https://doi.org/10.1016/j.artmed.2024.102988
UR  - https://www.sciencedirect.com/science/article/pii/S0933365724002306
KW  - Mental health
KW  - LLM
KW  - Triage
KW  - Clinical support
KW  - Efficiency
KW  - Attention
AB  - Contemporary large language models (LLMs) may have utility for processing unstructured, narrative free-text clinical data contained in electronic health records (EHRs) — a particularly important use-case for mental health where a majority of routinely-collected patient data lacks structured, machine-readable content. A significant problem for the United Kingdom’s National Health Service (NHS) are the long waiting lists for specialist mental healthcare. According to NHS data (NHS Digital, 2024), in each month of 2023, there were between 370,000 and 470,000 individual new referrals into secondary mental healthcare services. Referrals must be triaged by clinicians, using clinical information contained in the patient’s EHR to arrive at a decision about the most appropriate mental healthcare team to assess and potentially treat these patients. The ability to efficiently recommend a relevant team by ingesting potentially voluminous clinical notes could help services both reduce referral waiting times and with the right technology, improve the evidence available to justify triage decisions. We present and evaluate three different approaches for LLM-based, end-to-end ingestion of variable-length clinical EHR data to assist clinicians when triaging referrals. Our model is able to deliver triage recommendations consistent with existing clinical practices and its architecture was implemented on a single GPU, making it practical for implementation in resource-limited NHS environments where private implementations of LLM technology will be necessary to ensure confidential clinical data are appropriately controlled and governed. Code available at: https://github.com/NtaylorOX/BespokeLLM_Triage.
ER  - 

TY  - JOUR
T1  - A large language model-based platform for real-time building monitoring and occupant interaction
AU  - Xu, Yifang
AU  - Zhu, Siyao
AU  - Cai, Jiannan
AU  - Chen, Jianli
AU  - Li, Shuai
JO  - Journal of Building Engineering
VL  - 100
SP  - 111488
PY  - 2025
DA  - 2025/04/15/
SN  - 2352-7102
DO  - https://doi.org/10.1016/j.jobe.2024.111488
UR  - https://www.sciencedirect.com/science/article/pii/S2352710224030560
KW  - Building management
KW  - Health
KW  - Energy
KW  - Thermal comfort
KW  - Conversational persuading system
AB  - Effective management of indoor environments requires a comprehensive evaluation of health, energy consumption, and thermal comfort. However, real-time assessment of these factors is challenging due to the lack of integrated applications that combine IoT technology, real-time simulation, and user-friendly interfaces for communication. To address these challenges, this research introduces a novel platform specifically designed to manage health, energy consumption, and thermal comfort in smart buildings, leveraging IoT-based building information modeling (BIM), cloud computing, and an AI-powered conversational suggestion system based on the large language model (GPT). The platform integrates real-time monitoring, simulation, alerting, and persuasion capabilities to manage health, energy consumption, and thermal comfort, enabling responsive building environment controls by assessing tradeoffs among these dimensions and providing timely recommendations. Additionally, it employs persuasive techniques to encourage occupants to adopt environmentally-friendly practices. A case study in a university building demonstrated the platform's functionality and visualization capability. A survey assessing the persuasive system revealed high adoption rates—95.59 % for switching rooms to improve indoor air quality and health, and 79.90 % for adjusting clothing to enhance thermal comfort—indicating strong participant willingness to adopt sustainable practices through the platform's strategies. The key contribution of this research is the development of a comprehensive, real-time platform that enhances indoor environmental quality and sustainability through advanced monitoring, analysis, and social interaction.
ER  - 

TY  - JOUR
T1  - Fine-grained detoxification framework via instance-level prefixes for large language models
AU  - Yi, Xin
AU  - Wang, Linlin
AU  - Wang, Xiaoling
AU  - He, Liang
JO  - Neurocomputing
VL  - 611
SP  - 128684
PY  - 2025
DA  - 2025/01/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.128684
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224014553
KW  - Large language model
KW  - Detoxification framework
KW  - Safety and security
AB  - Large Language Models (LLMs) have demonstrated remarkable performance across various natural language processing (NLP) tasks. However, their practical usability is often compromised by a propensity to generate toxic content, such as insults, threats, and profanity, particularly in response to adversarial prompts. Several fine-tuning and decoding approaches have been employed to address this challenge to mitigate toxicity. Nevertheless, these methods typically necessitate additional resources, such as high-quality training data or auxiliary models, thereby incurring extra costs. In this paper, we propose a novel detoxification framework, Fine-Grained Detoxification via Instance-Level Prefixes (FGDILP), which effectively mitigates the generation of toxic text without incurring additional training costs. Specifically, FGDILP leverages contextualized representations in attention space by contrasting a positive prefix-prepended prompt against multiple negative prefix-prepended prompts at the instance level. This methodology facilitates the construction of fine-grained subtoxicity vectors, which are subsequently fused to adjust the original generation pathway when responding to raw prompts. Our results demonstrate that FGDILP enables controlled text generation concerning detoxification at both the utterance and context levels. While our method slightly impacts generation fluency and diversity, it significantly outperforms prompt-based baselines regarding detoxification effectiveness. Our code is available at https://github.com/xinykou/FGDILP.
ER  - 

TY  - JOUR
T1  - Unlocking employer insights: Using large language models to explore human-centric aspects in the context of industry 5.0
AU  - Grybauskas, Andrius
AU  - Cárdenas-Rubio, Jeisson
JO  - Technological Forecasting and Social Change
VL  - 208
SP  - 123719
PY  - 2024
DA  - 2024/11/01/
SN  - 0040-1625
DO  - https://doi.org/10.1016/j.techfore.2024.123719
UR  - https://www.sciencedirect.com/science/article/pii/S0040162524005171
KW  - Industry 5.0
KW  - Job vacancies
KW  - LLM
KW  - Well-being
KW  - Human-centricity
AB  - This paper aims to enhance the understanding of Industry 5.0 by introducing an innovative AI-based methodology that proficiently maps employer expressions related to well-being using job postings. This process involves creating a comprehensive dictionary of well-being expressions, which is then compared with existing academic literature. This approach facilitates empirical well-being analysis from employers’ perspectives. Bridging theoretical and practical realms, we offer valuable insights to academia and industry about well-being (human-centricity) interpretation by employers. The findings highlight UK employers’ prioritisation of self-realisation and a positive work atmosphere to attract job seekers. Nonetheless, many vacancies do not explicitly emphasise well-being to attract potential workers.
ER  - 

TY  - JOUR
T1  - A comprehensive evaluation of large Language models on benchmark biomedical text processing tasks
AU  - Jahan, Israt
AU  - Laskar, Md Tahmid Rahman
AU  - Peng, Chun
AU  - Huang, Jimmy Xiangji
JO  - Computers in Biology and Medicine
VL  - 171
SP  - 108189
PY  - 2024
DA  - 2024/03/01/
SN  - 0010-4825
DO  - https://doi.org/10.1016/j.compbiomed.2024.108189
UR  - https://www.sciencedirect.com/science/article/pii/S0010482524002737
KW  - Large language models
KW  - ChatGPT
KW  - PaLM
KW  - LLaMA
KW  - Claude
KW  - Transformer
KW  - Natural language processing
KW  - LLM evaluation
AB  - Recently, Large Language Models (LLMs) have demonstrated impressive capability to solve a wide range of tasks. However, despite their success across various tasks, no prior work has investigated their capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of LLMs on benchmark biomedical tasks. For this purpose, a comprehensive evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets has been conducted. To the best of our knowledge, this is the first work that conducts an extensive evaluation and comparison of various LLMs in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot LLMs even outperform the current state-of-the-art models when they were fine-tuned only on the training set of these datasets. This suggests that pre-training on large text corpora makes LLMs quite specialized even in the biomedical domain. We also find that not a single LLM can outperform other LLMs in all tasks, with the performance of different LLMs may vary depending on the task. While their performance is still quite poor in comparison to the biomedical models that were fine-tuned on large training sets, our findings demonstrate that LLMs have the potential to be a valuable tool for various biomedical tasks that lack large annotated data.
ER  - 

TY  - JOUR
T1  - Demystifying large language models in second language development research
AU  - Cong, Yan
JO  - Computer Speech & Language
VL  - 89
SP  - 101700
PY  - 2025
DA  - 2025/01/01/
SN  - 0885-2308
DO  - https://doi.org/10.1016/j.csl.2024.101700
UR  - https://www.sciencedirect.com/science/article/pii/S0885230824000834
KW  - Large language models
KW  - Natural language processing
KW  - Automatic essay scoring
KW  - L2 writing development
KW  - L2 interlanguage
KW  - Bilingualism
AB  - Evaluating students' textual response is a common and critical task in language research and education practice. However, manual assessment can be tedious and may lack consistency, posing challenges for both scientific discovery and frontline teaching. Leveraging state-of-the-art large language models (LLMs), we aim to define and operationalize LLM-Surprisal, a numeric representation of the interplay between lexical diversity and syntactic complexity, and to empirically and theoretically demonstrate its relevance for automatic writing assessment and Chinese L2 (second language) learners’ English writing development. We developed an LLM-based natural language processing pipeline that can automatically compute text Surprisal scores. By comparing Surprisal metrics with the widely used classic indices in L2 studies, we extended the usage of computational metrics in Chinese learners’ L2 English writing. Our analyses suggested that LLM-Surprisals can distinguish L2 from L1 (first language) writing, index L2 development stages, and predict scores provided by human professionals. This indicated that the Surprisal dimension may manifest itself as critical aspects in L2 development. The relative advantages and disadvantages of these approaches were discussed in depth. We concluded that LLMs are promising tools that can enhance L2 research. Our showcase paves the way for more nuanced approaches to computationally assessing and understanding L2 development. Our pipelines and findings will inspire language teachers, learners, and researchers to operationalize LLMs in an innovative and accessible manner.
ER  - 

TY  - JOUR
T1  - Establishing priorities for implementation of large language models in pathology and laboratory medicine
AU  - Arvisais-Anhalt, Simone
AU  - Gonias, Steven L.
AU  - Murray, Sara G.
JO  - Academic Pathology
VL  - 11
IS  - 1
SP  - 100101
PY  - 2024
DA  - 2024/01/01/
SN  - 2374-2895
DO  - https://doi.org/10.1016/j.acpath.2023.100101
UR  - https://www.sciencedirect.com/science/article/pii/S2374289523000337
KW  - Artificial intelligence
KW  - GPT
KW  - Large language models (LLMs)
AB  - Artificial intelligence and machine learning have numerous applications in pathology and laboratory medicine. The release of ChatGPT prompted speculation regarding the potentially transformative role of large-language models (LLMs) in academic pathology, laboratory medicine, and pathology education. Because of the potential to improve LLMs over the upcoming years, pathology and laboratory medicine clinicians are encouraged to embrace this technology, identify pathways by which LLMs may support our missions in education, clinical practice, and research, participate in the refinement of AI modalities, and design user-friendly interfaces that integrate these tools into our most important workflows. Challenges regarding the use of LLMs, which have already received considerable attention in a general sense, are also reviewed herein within the context of the pathology field and are important to consider as LLM applications are identified and operationalized.
ER  - 

TY  - JOUR
T1  - RAG-based explainable prediction of road users behaviors for automated driving using knowledge graphs and large language models
AU  - Hussien, Mohamed Manzour
AU  - Melo, Angie Nataly
AU  - Ballardini, Augusto Luis
AU  - Maldonado, Carlota Salinas
AU  - Izquierdo, Rubén
AU  - Sotelo, Miguel Ángel
JO  - Expert Systems with Applications
VL  - 265
SP  - 125914
PY  - 2025
DA  - 2025/03/15/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2024.125914
UR  - https://www.sciencedirect.com/science/article/pii/S0957417424027817
KW  - Road users’ behaviors
KW  - Explainable predictions
KW  - Pedestrian crossing actions
KW  - Lane change maneuvers
KW  - Autonomous driving
AB  - The prediction of road user behaviors in the context of autonomous driving has attracted considerable attention from the scientific community in recent years. Most works focus on predicting behaviors based on kinematic information alone, a simplification of reality since road users are humans, and as such they are highly influenced by their surrounding context. In addition, a large plethora of research works rely on powerful Deep Learning techniques, which exhibit high-performance metrics in prediction tasks but may lack the ability to fully understand and exploit the contextual semantic information contained in the road scene, not to mention their inability to provide explainable predictions that can be understood by humans. In this work, we propose an explainable road users’ behavior prediction system that integrates the reasoning abilities of Knowledge Graphs (KG) and the expressiveness capabilities of Large Language Models (LLM) by using Retrieval Augmented Generation (RAG) techniques. For that purpose, Knowledge Graph Embeddings (KGE) and Bayesian inference are combined to allow the deployment of a fully inductive reasoning system that enables the issuing of predictions that rely on legacy information contained in the graph, as well as on current evidence gathered in real-time by onboard sensors. Two use cases have been implemented following the proposed approach: 1) Prediction of pedestrians’ crossing actions; and 2) Prediction of lane change maneuvers. In both cases, the performance attained exceeds the current state-of-the-art in terms of anticipation and F1 score, showing a promising avenue for future research in this field.
ER  - 

TY  - JOUR
T1  - Applications and Concerns of ChatGPT and Other Conversational Large Language Models in Health Care: Systematic Review
AU  - Wang, Leyao
AU  - Wan, Zhiyu
AU  - Ni, Congning
AU  - Song, Qingyuan
AU  - Li, Yang
AU  - Clayton, Ellen
AU  - Malin, Bradley
AU  - Yin, Zhijun
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/22769
UR  - https://www.sciencedirect.com/science/article/pii/S143888712400757X
KW  - large language model
KW  - ChatGPT
KW  - artificial intelligence
KW  - natural language processing
KW  - health care
KW  - summarization
KW  - medical knowledge inquiry
KW  - reliability
KW  - bias
KW  - privacy
AB  - Background
The launch of ChatGPT (OpenAI) in November 2022 attracted public attention and academic interest to large language models (LLMs), facilitating the emergence of many other innovative LLMs. These LLMs have been applied in various fields, including health care. Numerous studies have since been conducted regarding how to use state-of-the-art LLMs in health-related scenarios.
Objective
This review aims to summarize applications of and concerns regarding conversational LLMs in health care and provide an agenda for future research in this field.
Methods
We used PubMed, ACM, and the IEEE digital libraries as primary sources for this review. We followed the guidance of PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) to screen and select peer-reviewed research articles that (1) were related to health care applications and conversational LLMs and (2) were published before September 1, 2023, the date when we started paper collection. We investigated these papers and classified them according to their applications and concerns.
Results
Our search initially identified 820 papers according to targeted keywords, out of which 65 (7.9%) papers met our criteria and were included in the review. The most popular conversational LLM was ChatGPT (60/65, 92% of papers), followed by Bard (Google LLC; 1/65, 2% of papers), LLaMA (Meta; 1/65, 2% of papers), and other LLMs (6/65, 9% papers). These papers were classified into four categories of applications: (1) summarization, (2) medical knowledge inquiry, (3) prediction (eg, diagnosis, treatment recommendation, and drug synergy), and (4) administration (eg, documentation and information collection), and four categories of concerns: (1) reliability (eg, training data quality, accuracy, interpretability, and consistency in responses), (2) bias, (3) privacy, and (4) public acceptability. There were 49 (75%) papers using LLMs for either summarization or medical knowledge inquiry, or both, and there are 58 (89%) papers expressing concerns about either reliability or bias, or both. We found that conversational LLMs exhibited promising results in summarization and providing general medical knowledge to patients with a relatively high accuracy. However, conversational LLMs such as ChatGPT are not always able to provide reliable answers to complex health-related tasks (eg, diagnosis) that require specialized domain expertise. While bias or privacy issues are often noted as concerns, no experiments in our reviewed papers thoughtfully examined how conversational LLMs lead to these issues in health care research.
Conclusions
Future studies should focus on improving the reliability of LLM applications in complex health-related tasks, as well as investigating the mechanisms of how LLM applications bring bias and privacy issues. Considering the vast accessibility of LLMs, legal, social, and technical efforts are all needed to address concerns about LLMs to promote, improve, and regularize the application of LLMs in health care.
ER  - 

TY  - JOUR
T1  - Viability of Open Large Language Models for Clinical Documentation in German Health Care: Real-World Model Evaluation Study
AU  - Heilmeyer, Felix
AU  - Böhringer, Daniel
AU  - Reinhard, Thomas
AU  - Arens, Sebastian
AU  - Lyssenko, Lisa
AU  - Haverkamp, Christian
JO  - JMIR Medical Informatics
VL  - 12
PY  - 2024
DA  - 2024/01/01/
SN  - 2291-9694
DO  - https://doi.org/10.2196/59617
UR  - https://www.sciencedirect.com/science/article/pii/S2291969424001091
KW  - machine learning
KW  - ML
KW  - artificial intelligence
KW  - AI
KW  - large language model
KW  - large language models
KW  - LLM
KW  - LLMs
KW  - natural language processing
KW  - NLP
KW  - deep learning
KW  - algorithm
KW  - algorithms
KW  - model
KW  - models
KW  - analytics
KW  - practical model
KW  - practical models
KW  - medical documentation
KW  - writing assistance
KW  - medical administration
KW  - writing assistance for physicians
AB  - Background
The use of large language models (LLMs) as writing assistance for medical professionals is a promising approach to reduce the time required for documentation, but there may be practical, ethical, and legal challenges in many jurisdictions complicating the use of the most powerful commercial LLM solutions.
Objective
In this study, we assessed the feasibility of using nonproprietary LLMs of the GPT variety as writing assistance for medical professionals in an on-premise setting with restricted compute resources, generating German medical text.
Methods
We trained four 7-billion–parameter models with 3 different architectures for our task and evaluated their performance using a powerful commercial LLM, namely Anthropic’s Claude-v2, as a rater. Based on this, we selected the best-performing model and evaluated its practical usability with 2 independent human raters on real-world data.
Results
In the automated evaluation with Claude-v2, BLOOM-CLP-German, a model trained from scratch on the German text, achieved the best results. In the manual evaluation by human experts, 95 (93.1%) of the 102 reports generated by that model were evaluated as usable as is or with only minor changes by both human raters.
Conclusions
The results show that even with restricted compute resources, it is possible to generate medical texts that are suitable for documentation in routine clinical practice. However, the target language should be considered in the model selection when processing non-English text.
ER  - 

TY  - JOUR
T1  - Streamlining conformity assessment of software applying large language models
AU  - Litzinger, János
AU  - Neumann, Jörg
AU  - Peters, Daniel
AU  - Thiel, Florian
JO  - Measurement: Sensors
SP  - 101792
PY  - 2025
DA  - 2025/01/07/
SN  - 2665-9174
DO  - https://doi.org/10.1016/j.measen.2024.101792
UR  - https://www.sciencedirect.com/science/article/pii/S2665917424007682
KW  - large language models
KW  - Natural language processing
KW  - Conformity assessment
KW  - Legal metrology
KW  - WELMEC
KW  - OIML
AB  - To reduce administrative burden and support technological innovations and their fast market entry is a worldwide political objective. This paper explores the application of large language models (LLMs) in enhancing and streamlining the process of conformity assessment for regulated measuring instruments. We delve into the methodologies for training and customizing LLMs to scrutinize documentation against the software requirements stipulated in the European Measuring Instrument Directive (MID). The discourse extends to selecting suitable LLMs, ensuring the quality of training data, and establishing benchmarks for input and output data quality. Moreover, it addresses the pivotal concerns of security, privacy, and trust when integrating LLMs into a digital twin or web-based service architecture. The application of the findings is exemplary demonstrated by the amendment of a document analysing tool already developed by PTB. This tool is regularly used in testing of complex software as part of legally regulated measuring instruments in Europe.
ER  - 

TY  - JOUR
T1  - Generative AI and Large Language Models - Benefits, Drawbacks, Future and Recommendations
AU  - Håkansson, Anne
AU  - Phillips-Wren, Gloria
JO  - Procedia Computer Science
VL  - 246
SP  - 5458
EP  - 5468
PY  - 2024
DA  - 2024/01/01/
T2  - 28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.09.689
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924027492
KW  - Natural Language Processing
KW  - Generative AI
KW  - Large Language Models
AB  - Natural language processing, with parsing and generation, has a long tradition. Parsing has been easier to perform than a generation but with generative artificial intelligence (a.k.a Gen AI) and large language models (abbr. LLMs), this has changed. Generative artificial intelligence is a type of artificial intelligence that uses a large data set to create something in the genre of that data set. It can generate different outputs ranging from texts, audio, objects, pictures, and paintings to videos, but also synthetic data. LLMs use deep learning and deep neural networks to train on large text corpora for recognizing and generating texts. These models are based on massive data sets, collected from databases and the web. They use transformer models to detect how elements in sequences relate to each other. This provides context support. Two well-known large language models are the Generative Pre-trained Transformer, GPT, used in ChatGPT and Bidirectional Encoder Representations from Transformers, BERT. Although LLMs have advantages, they have problems. This paper presents generative artificial intelligence and LLMs with benefits and drawbacks. Results from applying these models have shown that they can work well for accuracy in specificity, user personalization and human-computer communication but they may not provide acceptable, reliable and truthful results. For example, ethics, hallucinations and incorrect information, or misjudgments, are some major problems. The paper ends with future directions, research questions on LLMs, and recommendations.
ER  - 

TY  - JOUR
T1  - Large language models for biomolecular analysis: From methods to applications
AU  - Feng, Ruijun
AU  - Zhang, Chi
AU  - Zhang, Yang
JO  - TrAC Trends in Analytical Chemistry
VL  - 171
SP  - 117540
PY  - 2024
DA  - 2024/02/01/
SN  - 0165-9936
DO  - https://doi.org/10.1016/j.trac.2024.117540
UR  - https://www.sciencedirect.com/science/article/pii/S0165993624000220
KW  - Large language model
KW  - Biomolecular analysis
KW  - Fine-tuning
KW  - Prompt engineering
KW  - Parameter-efficient fine-tuning
KW  - In-context learning
KW  - Protein structure analysis
KW  - Protein sequence generation
KW  - Gene sequence analysis
KW  - Molecular representation learning
AB  - Large language models (LLMs) are proving to be very useful in many fields, especially chemistry and biology, because of their amazing capabilities. Biomolecular data is often represented sequentially, much like textual data used to train LLMs. However, developing LLMs from scratch requires a substantial amount of data and computational resources, which may not be feasible for most researchers. A more workable solution to this problem is to change the inputs or parameters so that the previously trained general LLMs can pick up the specific knowledge needed for biomolecular analysis. These adaption strategies lower the amount of data and hardware needed, providing a more affordable option. This review provides the introduction of two popular LLM adaptation techniques: fine-tuning and prompt engineering, along with their uses in the analysis of molecules, proteins, and genes. A thorough overview of current common datasets and pre-trained models is also provided. This review outlines the possible advantages and difficulties of LLMs for biomolecular analysis, opening the door for chemists and biologists to effectively utilize LLMs in their future studies.
ER  - 

TY  - JOUR
T1  - Evaluating Large Language Models for Automated Reporting and Data Systems Categorization: Cross-Sectional Study
AU  - Wu, Qingxia
AU  - Wu, Qingxia
AU  - Li, Huali
AU  - Wang, Yan
AU  - Bai, Yan
AU  - Wu, Yaping
AU  - Yu, Xuan
AU  - Li, Xiaodong
AU  - Dong, Pei
AU  - Xue, Jon
AU  - Shen, Dinggang
AU  - Wang, Meiyun
JO  - JMIR Medical Informatics
VL  - 12
PY  - 2024
DA  - 2024/01/01/
SN  - 2291-9694
DO  - https://doi.org/10.2196/55799
UR  - https://www.sciencedirect.com/science/article/pii/S2291969424000838
KW  - Radiology Reporting and Data Systems
KW  - LI-RADS
KW  - Lung-RADS
KW  - O-RADS
KW  - large language model
KW  - ChatGPT
KW  - chatbot
KW  - chatbots
KW  - categorization
KW  - recommendation
KW  - recommendations
KW  - accuracy
AB  - Background
Large language models show promise for improving radiology workflows, but their performance on structured radiological tasks such as Reporting and Data Systems (RADS) categorization remains unexplored.
Objective
This study aims to evaluate 3 large language model chatbots—Claude-2, GPT-3.5, and GPT-4—on assigning RADS categories to radiology reports and assess the impact of different prompting strategies.
Methods
This cross-sectional study compared 3 chatbots using 30 radiology reports (10 per RADS criteria), using a 3-level prompting strategy: zero-shot, few-shot, and guideline PDF-informed prompts. The cases were grounded in Liver Imaging Reporting & Data System (LI-RADS) version 2018, Lung CT (computed tomography) Screening Reporting & Data System (Lung-RADS) version 2022, and Ovarian-Adnexal Reporting & Data System (O-RADS) magnetic resonance imaging, meticulously prepared by board-certified radiologists. Each report underwent 6 assessments. Two blinded reviewers assessed the chatbots’ response at patient-level RADS categorization and overall ratings. The agreement across repetitions was assessed using Fleiss κ.
Results
Claude-2 achieved the highest accuracy in overall ratings with few-shot prompts and guideline PDFs (prompt-2), attaining 57% (17/30) average accuracy over 6 runs and 50% (15/30) accuracy with k-pass voting. Without prompt engineering, all chatbots performed poorly. The introduction of a structured exemplar prompt (prompt-1) increased the accuracy of overall ratings for all chatbots. Providing prompt-2 further improved Claude-2’s performance, an enhancement not replicated by GPT-4. The interrun agreement was substantial for Claude-2 (k=0.66 for overall rating and k=0.69 for RADS categorization), fair for GPT-4 (k=0.39 for both), and fair for GPT-3.5 (k=0.21 for overall rating and k=0.39 for RADS categorization). All chatbots showed significantly higher accuracy with LI-RADS version 2018 than with Lung-RADS version 2022 and O-RADS (P<.05); with prompt-2, Claude-2 achieved the highest overall rating accuracy of 75% (45/60) in LI-RADS version 2018.
Conclusions
When equipped with structured prompts and guideline PDFs, Claude-2 demonstrated potential in assigning RADS categories to radiology cases according to established criteria such as LI-RADS version 2018. However, the current generation of chatbots lags in accurately categorizing cases based on more recent RADS criteria.
ER  - 

TY  - JOUR
T1  - Visual large language model for wheat disease diagnosis in the wild
AU  - Zhang, Kunpeng
AU  - Ma, Li
AU  - Cui, Beibei
AU  - Li, Xin
AU  - Zhang, Boqiang
AU  - Xie, Na
JO  - Computers and Electronics in Agriculture
VL  - 227
SP  - 109587
PY  - 2024
DA  - 2024/12/01/
SN  - 0168-1699
DO  - https://doi.org/10.1016/j.compag.2024.109587
UR  - https://www.sciencedirect.com/science/article/pii/S0168169924009785
KW  - Plant disease
KW  - Wheat disease diagnosis
KW  - Wheat disease classification
KW  - Large language model
KW  - Explainable AI
AB  - Early detection of symptoms in wheat plants is crucial for mitigating disease effects and preventing their spread. Prompt phytosanitary treatment minimizes yield losses and enhances treatment efficacy. In recent years, numerous image analysis-based methodologies for automatic disease identification have been developed, with Convolutional Neural Networks (CNNs) achieving notable success in visual classification tasks. The existing methods often lack the necessary intelligence and reasoning for real-world applications. This study introduces an advanced wheat disease diagnosis approach using a Visual Language Model (VLM), named the Wheat Disease Language Model (WDLM). The WDLM first leverages the modified Segment Anything Model (SAM) to isolate key wheat features from complex wild environments. To enhance the logical reasoning abilities, the WDLM integrates a reasoning chain to generate clear, reasoned explanations for its diagnosis. By employing dedicated prompt engineering, this study establishes the Wheat Disease Semantic Dataset (WDSD) to fine-tune the VLM. The WDSD, which includes a diverse set of wheat images from various sources, bridges the gap between advanced VLM technology and wheat pathology. Tailored with task-specific data, the WDLM demonstrates superior intelligence by providing accurate classification of wheat diseases and suggesting potential treatment options. Compared to CNN-based models, Transformer-based models, and other VLMs, the WDLM shows improved performance in various scenarios. Integrated with mobile applications, the WDLM approach is readily applicable in the field, representing a promising advancement in the intelligent diagnosis of wheat diseases.
ER  - 

TY  - JOUR
T1  - A safety realignment framework via subspace-oriented model fusion for large language models
AU  - Yi, Xin
AU  - Zheng, Shunfan
AU  - Wang, Linlin
AU  - Wang, Xiaoling
AU  - He, Liang
JO  - Knowledge-Based Systems
VL  - 306
SP  - 112701
PY  - 2024
DA  - 2024/12/20/
SN  - 0950-7051
DO  - https://doi.org/10.1016/j.knosys.2024.112701
UR  - https://www.sciencedirect.com/science/article/pii/S0950705124013352
KW  - Large language model
KW  - Model fusion
KW  - Safety alignment
AB  - To improve the performance of large language models (LLMs) on specific tasks, task-specific instruction fine-tuning is essential. However, this process can easily compromise the safety of a task-specific model, making it susceptible to obeying malicious instructions and generating harmful content. Current methods against fine-tuning attack usually interfere with the original fine-tuning objectives or require substantial amounts of data to realign the compromised model. To address these two major challenges, we propose reusing the initial aligned model and realigning task-specific model in the safety subspace. In this paper, we introduce a safety realignment framework through subspace-oriented model fusion (SOMF), aiming to transfer the safeguard capabilities of an initially aligned model into the current task-specific model. Our approach begins by disentangling all task vectors from the parameters of each task-specific model. We then identify safety-critical regions within these vectors by subspace masking techniques. Finally, we fuse the initial safely aligned LLM with all task vectors based on the identified safety subspace to restore the model’s safety properties. Our experiments confirm that our safety realignment framework satisfies the safety requirements of an independent task-specific model as well as traditional multitask models during their fusion. Our findings confirm that SOMF preserves safety without notably compromising performance on specific tasks while exhibiting higher data efficiency. The code is publicly available at https://github.com/xinykou/safety_realignment.
ER  - 

TY  - JOUR
T1  - 8. Agreement of Large Language Models with Humans in Extracting Data from Unstructured Records of Multiple Sclerosis Patients
AU  - Alnhwi, Zainab Ali
AU  - Aleisa, Faisal Saleh
AU  - Almutawa, Walaa Fahad
AU  - Alamro, Hamad Saleh
AU  - Alanazi, Atheer Hussain
AU  - Aljouie, Abdulrhman
AU  - Abulaban, Ahmad
JO  - Multiple Sclerosis and Related Disorders
VL  - 92
SP  - 105969
PY  - 2024
DA  - 2024/12/01/
SN  - 2211-0348
DO  - https://doi.org/10.1016/j.msard.2024.105969
UR  - https://www.sciencedirect.com/science/article/pii/S2211034824005455
AB  - Background/Objective(s)
Multiple Sclerosis (MS) is a chronic autoimmune disorder affecting the central nervous system, leading to progressive neurological dysfunction, occurs in individuals aged 20-40 years. Monitoring MS progression often involves the Expanded Disability Status Scale (EDSS), though its accuracy can be compromised in elderly patients with comorbidities. Artificial Intelligence (AI) and Large Language Models (LLMs) have revolutionized data analysis and decision-making processes in healthcare. Machine Learning (ML), a core component of AI, enhances its efficacy through data-driven learning, particularly in Natural Language Processing (NLP) applications which extract information from narrative data. LLMs, exemplified by models like GPT-4, generate human-like responses by utilizing self-supervised learning techniques and extensive text training. Recent studies have highlighted the capabilities of LLMs in medical data tasks, such as calculating medical scores and extracting information from clinical notes. However, no studies have compared LLMs with human performance in extracting data specifically from unstructured MS patient records. This study aims to measure the agreement between LLMs and humans in extracting data from unstructured records of MS patients at the National Guard Health Affairs (NGHA) in Saudi Arabia, highlighting the potential and limitations of LLMs in this context.
Material(s) and Method(s)
This cross-sectional study was conducted at King Abdulaziz Medical City (KAMC) and King Abdullah International Medical Research Centre (KAIMRC). A total of 382 patients diagnosed with MS, aged over 14 years, were included. Patients with atypical MS presentations or incomplete medical records were excluded. The primary variables of interest were EDSS scores, Disease-Modifying Therapies (DMTs), and the number and characteristics of relapses. Secondary variables included patient demographics, smoking status, body metrics, date of first MS symptoms, diagnosis date, secondary diseases, and MRI findings. Data were extracted from clinical notes using a Phi-3 Mini 128K LLM running on a local AI workstation, with manual data extraction for comparison by trained students. Statistical analyses included the Kappa coefficient for categorical variables and the Intraclass Correlation Coefficient (ICC) for numerical variables, with significance set at p < 0.05. Analyses were conducted using SAS 9.4 on an AI workstation equipped with an AMD threadripper pro CPU, 258 GB of memory, and two NVIDIA RTX A6000 GPUs.
Result(s)
The analysis revealed that the agreement between human annotators and the Phi-3 Mini LLM for extracting clinical data from unstructured MS patient records was lower than expected. The ICC for the EDSS and the number of clinical relapses were -0.4123 and 0.3848, respectively, indicating weak agreement. The model demonstrated limited ability in identifying the first MS attack symptoms, with a Kappa value of 0.3976, and in recognizing the initial DMT used, with a particularly low Kappa value of 0.0077. These findings highlight the challenges faced by the LLM in accurately interpreting and extracting information from unstructured narrative data. However, the LLM performed better in extracting data related to sensory clinical relapses, achieving a higher Kappa value compared to other data types. This suggests that standardized reporting practices in medical records for specific clinical characteristics, such as sensory relapses, may enhance LLM accuracy. Overall, human annotators consistently outperformed the LLM in most clinical data extraction tasks.
Conclusion(s)
The agreement evaluation between trained students and LLM, in area of EDSS, number of attacks, 1st attack symptoms, and 1st DMT use, showed a weak agreement. Due to the computational limitations we had used SLM with few parameters which might explain the poor resutls, further study with larger language models, such as, Lama3.1(400B) could yield more positive results. Following the personal data protection law(PDPL), and to protect patient's privacy, a limited version of LLM was used, which showed a limitation for the study, due to time constraints and sample size overload on Phi3 mini model. The Kappa inter-rater agreement revealed that Phi3 mini did better in sensory clinical relapse compared to other types.
ER  - 

TY  - JOUR
T1  - Large language models present new questions for decision support
AU  - Handler, Abram
AU  - Larsen, Kai R.
AU  - Hackathorn, Richard
JO  - International Journal of Information Management
VL  - 79
SP  - 102811
PY  - 2024
DA  - 2024/12/01/
SN  - 0268-4012
DO  - https://doi.org/10.1016/j.ijinfomgt.2024.102811
UR  - https://www.sciencedirect.com/science/article/pii/S0268401224000598
KW  - Decision support systems
KW  - Generative artificial intelligence
KW  - Large language models
KW  - Natural language processing
KW  - Business intelligence
AB  - Large language models (LLMs) have proven capable of assisting with many aspects of organizational decision making, such as helping to collect information from databases and helping to brainstorm possible courses of action ahead of making a choice. We propose that broad adoption of these technologies introduces new questions in the study of decision support systems, which assist people with complex and open-ended choices in business. Where traditional study of decision support has focused on bespoke tools to solve narrow problems in specific domains, LLMs offer a general-purpose decision support technology which can be applied in many contexts. To organize the wealth of new questions which result from this shift, we turn to a classic framework from Herbert Simon, which proposes that decision making requires collecting evidence, considering alternatives, and finally making a choice. Working from Simon’s framework, we describe how LLMs introduce new questions at each stage of this decision-making process. We then group new questions into three overarching themes for future research, centered on how LLMs will change individual decision making, how LLMs will change organizational decision making, and how to design new decision support technologies which make use of the new capabilities of LLMs.
ER  - 

TY  - JOUR
T1  - The Application of Large Language Models for Radiologic Decision Making
AU  - Zaki, Hossam A.
AU  - Aoun, Andrew
AU  - Munshi, Saminah
AU  - Abdel-Megid, Hazem
AU  - Nazario-Johnson, Lleayem
AU  - Ahn, Sun Ho
JO  - Journal of the American College of Radiology
VL  - 21
IS  - 7
SP  - 1072
EP  - 1078
PY  - 2024
DA  - 2024/07/01/
SN  - 1546-1440
DO  - https://doi.org/10.1016/j.jacr.2024.01.007
UR  - https://www.sciencedirect.com/science/article/pii/S1546144024000565
KW  - Artificial intelligence
KW  - clinical decision making
KW  - ChatGPT
AB  - Background and purpose
Large language models (LLMs) have seen explosive growth, but their potential role in medical applications remains underexplored. Our study investigates the capability of LLMs to predict the most appropriate imaging study for specific clinical presentations in various subspecialty areas in radiology.
Methods and materials
Chat Generative Pretrained Transformer (ChatGPT), by OpenAI and Glass AI by Glass Health were tested on 1,075 clinical scenarios from 11 ACR expert panels to determine the most appropriate imaging study, benchmarked against the ACR Appropriateness Criteria. Two responses per clinical presentation were generated and averaged for the final clinical presentation score. Clinical presentation scores for each topic area were averaged as its final score. The average of the topic scores within a panel determined the final score of each panel. LLM responses were on a scale of 0 to 3. Partial scores were given for nonspecific answers. Pearson correlation coefficient (R-value) was calculated for each panel to determine a context-specific performance.
Results
Glass AI scored significantly higher than ChatGPT (2.32 ± 0.67 versus 2.08 ± 0.74, P = .002). Both LLMs performed the best in the Polytrauma, Breast, and Vascular panels, and performed the worst in the Neurologic, Musculoskeletal, and Cardiac panels. Glass AI outperformed ChatGPT in 10 of 11 panels, except Obstetrics and Gynecology. Maximum agreement was in the Pediatrics, Neurologic, and Thoracic panels, and the most disagreement occurred in the Vascular, Breast, and Urologic panels.
Conclusion
LLMs can be used to predict imaging studies, with Glass AI’s superior performance indicating the benefits of extra medical-text training. This supports the potential of LLMs in radiologic decision making.
ER  - 

TY  - JOUR
T1  - Sentiment analysis of the United States public support of nuclear power on social media using large language models
AU  - Kwon, O. Hwang
AU  - Vu, Katie
AU  - Bhargava, Naman
AU  - Radaideh, Mohammed I.
AU  - Cooper, Jacob
AU  - Joynt, Veda
AU  - Radaideh, Majdi I.
JO  - Renewable and Sustainable Energy Reviews
VL  - 200
SP  - 114570
PY  - 2024
DA  - 2024/08/01/
SN  - 1364-0321
DO  - https://doi.org/10.1016/j.rser.2024.114570
UR  - https://www.sciencedirect.com/science/article/pii/S136403212400296X
KW  - Sentiment analysis
KW  - Natural language processing
KW  - Nuclear power
KW  - Public policy
KW  - Social media
KW  - Large language models
AB  - This study utilized large language models (LLMs) to analyze public sentiment in the United States (US) regarding nuclear power on social media, focusing on X/Twitter, considering climate change challenges and advancements in nuclear power technology. Approximately, 1.26 million nuclear tweets from 2008–2023 were examined to fine-tune LLMs for sentiment classification. We found the crucial role of accurate data labeling for model performance, with potential implications for a 15% improvement, achieved through high-confidence labels. LLMs demonstrated better performance compared to traditional machine learning classifiers, with reduced susceptibility to overfitting and up to 96% classification accuracy. LLMs are used to segment the US public tweets into policy and energy-related categories, revealing that 68% are politically themed. Policy tweets tended to convey negative sentiment, often reflecting opposing political perspectives and focusing on nuclear deals and international relations. Energy-related tweets covered diverse topics with predominantly neutral to positive sentiment, indicating broad support for nuclear power in 48 out of 50 US states. The US public positive sentiments toward nuclear power stemmed from its high power density, reliability regardless of weather conditions, environmental benefits, application versatility, and recent innovations and advancements in both fission and fusion technologies. Negative sentiments primarily focused on waste management, high capital costs, and safety concerns. The neutral campaign highlighted global nuclear facts and advancements, with varying tones leaning towards positivity or negativity. An interesting neutral theme was the advocacy for the combined use of renewable and nuclear energy to attain net-zero goals.
ER  - 

TY  - JOUR
T1  - Potential applications of innovative AI-based tools in hydrogen energy development: Leveraging large language model technologies
AU  - Shahin, Matin
AU  - Simjoo, Mohammad
JO  - International Journal of Hydrogen Energy
VL  - 102
SP  - 918
EP  - 936
PY  - 2025
DA  - 2025/02/10/
SN  - 0360-3199
DO  - https://doi.org/10.1016/j.ijhydene.2025.01.066
UR  - https://www.sciencedirect.com/science/article/pii/S0360319925000710
KW  - Hydrogen energy
KW  - Artificial intelligence
KW  - Large language models
KW  - ChatGPT
KW  - Deep learning
AB  - Renewable energy development is crucial due to fossil fuels' environmental impact. Hydrogen energy, a promising alternative to reduce emissions, faces challenges in production, storage, and distribution. This paper explores the applications of ChatGPT, a large language model by OpenAI, in revolutionizing hydrogen energy research and development. The study investigates the advantages, limitations, and future outlook of AI and ChatGPT in accelerating hydrogen adoption during energy transition. To demonstrate ChatGPT's capabilities, four case studies were executed: (1) Evaluation of hydrogen production processes, identifying solid oxide electrolysis as the most efficient technology; (2) Implementation of an LSTM-based predictive maintenance system for hydrogen facilities, achieving 97% accuracy; (3) Analysis of policy impacts on hydrogen adoption, demonstrating carbon pricing's effectiveness; (4) Development of an XGBoost model for hydrogen production forecasting, achieving an R2 of 0.9996. The results of this study highlight ChatGPT's transformative potential in optimizing various aspects of hydrogen energy development, accelerating the transition to a sustainable energy future.
ER  - 

TY  - CHAP
T1  - Large Language Models for Pathway Curation: A Preliminary Investigation
AU  - Karkera, Nikitha
AU  - Karkera, Nikshita
AU  - Kumar, Mahanash
AU  - Srinivasulu, Vishnuvardhan P.
AU  - Ghosh, Samik
AU  - Palaniappan, Sucheendra K.
BT  - Reference Module in Life Sciences
PB  - Elsevier
PY  - 2024
DA  - 2024/01/01/
SN  - 978-0-12-809633-8
DO  - https://doi.org/10.1016/B978-0-323-95502-7.00254-2
UR  - https://www.sciencedirect.com/science/article/pii/B9780323955027002542
KW  - Generative AI
KW  - Gpt3.5
KW  - Gpt4
KW  - LLM
KW  - Pathway curation
AB  - The pathway curation task involves analyzing scientific literature to identify and represent cellular processes as pathways. This process, often time-consuming and labor-intensive, requires significant curation efforts amidst the rapidly growing biomedical literature. Natural Language Processing (NLP) offers a promising method to automatically extract these interactions from scientific texts. Despite immense progress, there remains room for improvement in these systems. The emergence of Large Language Models (LLMs) provides a promising solution for this challenge. Our study conducts a preliminary investigation into leveraging LLMs for the pathway curation task. This paper first presents a review of the current state-of-the-art algorithms for the pathway curation task. Our objective is to check the feasibility and formulate strategies of using these LLMs to improve the accuracy of pathway curation task. Our experiments demonstrate that our GPT-3.5 based fine-tuned models outperforms existing state-of-the-art methods. Specifically, our model achieved a 10 basis point improvement in overall recall and F1 score compared to the best existing algorithms. These findings highlight the potential of LLMs in pathway curation tasks, warranting further research and substantial efforts in this direction.
ER  - 

TY  - JOUR
T1  - The emergent role of artificial intelligence, natural learning processing, and large language models in higher education and research
AU  - Alqahtani, Tariq
AU  - Badreldin, Hisham A.
AU  - Alrashed, Mohammed
AU  - Alshaya, Abdulrahman I.
AU  - Alghamdi, Sahar S.
AU  - bin Saleh, Khalid
AU  - Alowais, Shuroug A.
AU  - Alshaya, Omar A.
AU  - Rahman, Ishrat
AU  - Al Yami, Majed S.
AU  - Albekairy, Abdulkareem M.
JO  - Research in Social and Administrative Pharmacy
VL  - 19
IS  - 8
SP  - 1236
EP  - 1242
PY  - 2023
DA  - 2023/08/01/
SN  - 1551-7411
DO  - https://doi.org/10.1016/j.sapharm.2023.05.016
UR  - https://www.sciencedirect.com/science/article/pii/S1551741123002802
KW  - Artificial intelligence
KW  - Pharmacy
KW  - Education
KW  - Research
KW  - Natural language processing
KW  - Large language models
AB  - Artificial Intelligence (AI) has revolutionized various domains, including education and research. Natural language processing (NLP) techniques and large language models (LLMs) such as GPT-4 and BARD have significantly advanced our comprehension and application of AI in these fields. This paper provides an in-depth introduction to AI, NLP, and LLMs, discussing their potential impact on education and research. By exploring the advantages, challenges, and innovative applications of these technologies, this review gives educators, researchers, students, and readers a comprehensive view of how AI could shape educational and research practices in the future, ultimately leading to improved outcomes. Key applications discussed in the field of research include text generation, data analysis and interpretation, literature review, formatting and editing, and peer review. AI applications in academics and education include educational support and constructive feedback, assessment, grading, tailored curricula, personalized career guidance, and mental health support. Addressing the challenges associated with these technologies, such as ethical concerns and algorithmic biases, is essential for maximizing their potential to improve education and research outcomes. Ultimately, the paper aims to contribute to the ongoing discussion about the role of AI in education and research and highlight its potential to lead to better outcomes for students, educators, and researchers.
ER  - 

TY  - JOUR
T1  - Leveraging Open-Source Large Language Models for Data Augmentation in Hospital Staff Surveys: Mixed Methods Study
AU  - Ehrett, Carl
AU  - Hegde, Sudeep
AU  - Andre, Kwame
AU  - Liu, Dixizi
AU  - Wilson, Timothy
JO  - JMIR Medical Education
VL  - 10
PY  - 2024
DA  - 2024/01/01/
SN  - 2369-3762
DO  - https://doi.org/10.2196/51433
UR  - https://www.sciencedirect.com/science/article/pii/S2369376224001399
KW  - data augmentation
KW  - large language models
KW  - medical education
KW  - natural language processing
KW  - data security
KW  - ethics
KW  - AI
KW  - artificial intelligence
KW  - data privacy
KW  - medical staff
AB  - Background
Generative large language models (LLMs) have the potential to revolutionize medical education by generating tailored learning materials, enhancing teaching efficiency, and improving learner engagement. However, the application of LLMs in health care settings, particularly for augmenting small datasets in text classification tasks, remains underexplored, particularly for cost- and privacy-conscious applications that do not permit the use of third-party services such as OpenAI’s ChatGPT.
Objective
This study aims to explore the use of open-source LLMs, such as Large Language Model Meta AI (LLaMA) and Alpaca models, for data augmentation in a specific text classification task related to hospital staff surveys.
Methods
The surveys were designed to elicit narratives of everyday adaptation by frontline radiology staff during the initial phase of the COVID-19 pandemic. A 2-step process of data augmentation and text classification was conducted. The study generated synthetic data similar to the survey reports using 4 generative LLMs for data augmentation. A different set of 3 classifier LLMs was then used to classify the augmented text for thematic categories. The study evaluated performance on the classification task.
Results
The overall best-performing combination of LLMs, temperature, classifier, and number of synthetic data cases is via augmentation with LLaMA 7B at temperature 0.7 with 100 augments, using Robustly Optimized BERT Pretraining Approach (RoBERTa) for the classification task, achieving an average area under the receiver operating characteristic (AUC) curve of 0.87 (SD 0.02; ie, 1 SD). The results demonstrate that open-source LLMs can enhance text classifiers’ performance for small datasets in health care contexts, providing promising pathways for improving medical education processes and patient care practices.
Conclusions
The study demonstrates the value of data augmentation with open-source LLMs, highlights the importance of privacy and ethical considerations when using LLMs, and suggests future directions for research in this field.
ER  - 

TY  - JOUR
T1  - Benchmarking Large Language Models for Cervical Spondylosis
AU  - Zhang, Boyan
AU  - Du, Yueqi
AU  - Duan, Wanru
AU  - Chen, Zan
JO  - JMIR Formative Research
VL  - 8
PY  - 2024
DA  - 2024/01/01/
SN  - 2561-326X
DO  - https://doi.org/10.2196/55577
UR  - https://www.sciencedirect.com/science/article/pii/S2561326X24004293
KW  - cervical spondylosis
KW  - large language model
KW  - LLM
KW  - patient
KW  - ChatGPT
AB  - Cervical spondylosis is the most common degenerative spinal disorder in modern societies. Patients require a great deal of medical knowledge, and large language models (LLMs) offer patients a novel and convenient tool for accessing medical advice. In this study, we collected the most frequently asked questions by patients with cervical spondylosis in clinical work and internet consultations. The accuracy of the answers provided by LLMs was evaluated and graded by 3 experienced spinal surgeons. Comparative analysis of responses showed that all LLMs could provide satisfactory results, and that among them, GPT-4 had the highest accuracy rate. Variation across each section in all LLMs revealed their ability boundaries and the development direction of artificial intelligence.
ER  - 

TY  - JOUR
T1  - An input-denoising-based defense against stealthy backdoor attacks in large language models for code
AU  - Qu, Yubin
AU  - Huang, Song
AU  - Chen, Xiang
AU  - Bai, Tongtong
AU  - Yao, Yongming
JO  - Information and Software Technology
VL  - 180
SP  - 107661
PY  - 2025
DA  - 2025/04/01/
SN  - 0950-5849
DO  - https://doi.org/10.1016/j.infsof.2024.107661
UR  - https://www.sciencedirect.com/science/article/pii/S0950584924002660
KW  - Deep neural networks
KW  - Triggers
KW  - Large language models for code
KW  - Backdoor attacks
AB  - Context:
Large Language Models are becoming integral to software development. They are trained on open data from platforms like GitHub, making them vulnerable to poisoning attacks. Research shows that backdoor attacks with traditional static triggers using fixed code patterns are relatively easy to detect. The novel attack approach uses specific Syntax Tree structures as triggers, offering greater stealthiness while maintaining explicit code structures. This method poses new challenges for backdoor detection.
Objective:
We propose an Input-D enoising-based defense against stealthy Backdoor Attacks with dynamic triggers (IDBA) in Large Language Models for Code.
Method:
We overlay a set of malicious code segments onto the code segment with dynamic triggers, convert the output state of the input code into a random walk graph neural network, calculate the expected value of the final state through particle filtering, and thus detect the existence of a backdoor attack.
Results:
Empirical studies are conducted on Codebert, GraphCodebert, and CodeT5 for vulnerability and code clone detection tasks. Our results show that IDBA achieves an average detection rate of 73.75% and 68.12% for vulnerability and code clone detection tasks, respectively.
Conclusion:
Detecting backdoor attacks using IDBA on code models allows for the early identification of potential backdoor threats after model deployment, enhancing the security of code models.
ER  - 

TY  - JOUR
T1  - Prompting large language models for user simulation in task-oriented dialogue systems
AU  - Algherairy, Atheer
AU  - Ahmed, Moataz
JO  - Computer Speech & Language
VL  - 89
SP  - 101697
PY  - 2025
DA  - 2025/01/01/
SN  - 0885-2308
DO  - https://doi.org/10.1016/j.csl.2024.101697
UR  - https://www.sciencedirect.com/science/article/pii/S0885230824000809
KW  - Task Oriented Dialogue
KW  - User simulator
KW  - Large language models
KW  - Prompting
KW  - Agenda-based simulator
AB  - Large Language Models (LLMs) have gained widespread popularity due to their instruction-following abilities. In this study, we evaluate their ability in simulating user interactions for task-oriented dialogue (TOD) systems. Our findings demonstrate that prompting LLMs reveals their promising capabilities for training and testing dialogue policies, eliminating the need for domain expertise in crafting complex rules or relying on large annotated data, as required by traditional simulators. The results show that the dialogue system trained with the ChatGPT simulator achieves a success rate of 59%, comparable to a 62% success rate of the dialogue system trained with the manual-rules, agenda-based user simulator (ABUS). Furthermore, the dialogue system trained with the ChatGPT simulator demonstrates better generalization ability compared to the dialogue system trained with the ABUS. Its success rate outperforms that of the dialogue system trained with the ABUS by 4% on GenTUS, 5% on the ChatGPT Simulator, and 3% on the Llama simulator. Nevertheless, LLM-based user simulators provide challenging environment, lexically rich, diverse, and random responses. Llama simulator outperforms the human reference in all lexical diversity metrics with a margin of 0.66 in SE, 0.39 in CE, 0.01 in MSTTR, 0.04 in HDD, and 0.55 in MTLD, while the ChatGPT simulator achieves comparable results. This ultimately contributes to enhancing the system’s ability to generalize more effectively.
ER  - 

TY  - JOUR
T1  - Multimodal Large Language Models in Health Care: Applications, Challenges, and Future Outlook
AU  - AlSaad, Rawan
AU  - Abd-alrazaq, Alaa
AU  - Boughorbel, Sabri
AU  - Ahmed, Arfan
AU  - Renault, Max-Antoine
AU  - Damseh, Rafat
AU  - Sheikh, Javaid
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/59505
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124005983
KW  - artificial intelligence
KW  - large language models
KW  - multimodal large language models
KW  - multimodality
KW  - multimodal generative artificial intelligence
KW  - multimodal generative AI
KW  - generative artificial intelligence
KW  - generative AI
KW  - health care
AB  - In the complex and multidimensional field of medicine, multimodal data are prevalent and crucial for informed clinical decisions. Multimodal data span a broad spectrum of data types, including medical images (eg, MRI and CT scans), time-series data (eg, sensor data from wearable devices and electronic health records), audio recordings (eg, heart and respiratory sounds and patient interviews), text (eg, clinical notes and research articles), videos (eg, surgical procedures), and omics data (eg, genomics and proteomics). While advancements in large language models (LLMs) have enabled new applications for knowledge retrieval and processing in the medical field, most LLMs remain limited to processing unimodal data, typically text-based content, and often overlook the importance of integrating the diverse data modalities encountered in clinical practice. This paper aims to present a detailed, practical, and solution-oriented perspective on the use of multimodal LLMs (M-LLMs) in the medical field. Our investigation spanned M-LLM foundational principles, current and potential applications, technical and ethical challenges, and future research directions. By connecting these elements, we aimed to provide a comprehensive framework that links diverse aspects of M-LLMs, offering a unified vision for their future in health care. This approach aims to guide both future research and practical implementations of M-LLMs in health care, positioning them as a paradigm shift toward integrated, multimodal data–driven medical practice. We anticipate that this work will spark further discussion and inspire the development of innovative approaches in the next generation of medical M-LLM systems.
ER  - 

TY  - JOUR
T1  - ZVQAF: Zero-shot visual question answering with feedback from large language models
AU  - Liu, Cheng
AU  - Wang, Chao
AU  - Peng, Yan
AU  - Li, Zhixu
JO  - Neurocomputing
VL  - 580
SP  - 127505
PY  - 2024
DA  - 2024/05/01/
SN  - 0925-2312
DO  - https://doi.org/10.1016/j.neucom.2024.127505
UR  - https://www.sciencedirect.com/science/article/pii/S0925231224002765
KW  - Feedback
KW  - Large language model
KW  - Visual question answering
AB  - Due to the prominent zero-shot generalization in new language tasks shown by large language models (LLMs), applying LLMs for zero-shot visual question answering (VQA) has been a new trend. However, most prior approaches directly use off-the-shelf captioning models to generate captions that compose in-context examples for LLMs, and such generated captions may be uninformative, thus leading the LLMs to give false predictions. To address this, we propose zero-shot VQA with feedback from LLMs (ZVQAF), a framework that applies LLMs to discriminate the quality of generated captions and leverages this feedback to train the captioning model. ZVQAF consists of two stages: the first stage is the training with feedback, which enables the captioning model to recognize the task objective and information requirements from the LLM, and the second stage is utilizing the optimized captioning model and LLM for inference. Extensive experiments show that ZVQAF achieves zero-shot VQA performance that is comparable or even superior to those previous zero-shot, few-shot, and end-to-end training approaches. For example, on VQAv2 test dataset, ZVQAF outperforms Flamingo (Alayrac et al., 2022) which employs end-to-end training by a large margin of 8.0%. In addition, on A-OKVQA dataset, ZVQAF outperforms zero-shot method Img2LLM (Guo et al., 2023) by 3.8% when employing LLMs with similar scales.
ER  - 

TY  - JOUR
T1  - What's in this LCA Report? A Case Study on Harnessing Large Language Models to Support Designers in Understanding Life Cycle Reports
AU  - Goridkov, Nicole
AU  - Wang, Ye
AU  - Goucher-Lambert, Kosa
JO  - Procedia CIRP
VL  - 122
SP  - 964
EP  - 969
PY  - 2024
DA  - 2024/01/01/
T2  - 31st CIRP Conference on Life Cycle Engineering
SN  - 2212-8271
DO  - https://doi.org/10.1016/j.procir.2024.01.131
UR  - https://www.sciencedirect.com/science/article/pii/S2212827124001756
KW  - sustainable design
KW  - life cycle reports
KW  - document understanding
KW  - knowledge management
KW  - large language models
AB  - Life cycle assessment (LCA) is a well-established approach and benchmark for design for sustainability efforts, in which detailed reports are produced that can serve as decision-making guides for developing new products. However, LCA reports are typically dense and technically complex, making it difficult for many engineering design project stakeholders to appropriately leverage the information found within them. Our work seeks to understand and improve the transfer of knowledge from LCA reports during the early stages of the design process, specifically leveraging the natural language capabilities of large language models (LLMs). In this paper, we investigate how four LCA-and sustainability-centric prompting frameworks can extract relevant design knowledge from LCA reports, demonstrated through a case study where an LLM (ChatGPT) is prompted on a provided electric toothbrush LCA report. Key findings illustrate the prompting frameworks can establish high-level summaries and identify life-cycle specific information, but the development of specific and design-focused sub-prompts will allow for richer understanding. We envision designers can use these proposed frameworks to query an LLM to gain context and insights from relevant LCA reports. The proposed techniques serve as a basis for automatic knowledge extraction from life cycle documents, creating accessible information in a user-friendly manner for designers who look to develop life-cycle-informed products.
ER  - 

TY  - JOUR
T1  - Redefining Health Care Data Interoperability: Empirical Exploration of Large Language Models in Information Exchange
AU  - Yoon, Dukyong
AU  - Han, Changho
AU  - Kim, Dong Won
AU  - Kim, Songsoo
AU  - Bae, SungA
AU  - Ryu, Jee An
AU  - Choi, Yujin
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/56614
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124002875
KW  - health care interoperability
KW  - large language models
KW  - medical data transformation
KW  - data standardization
KW  - text-based
AB  - Background
Efficient data exchange and health care interoperability are impeded by medical records often being in nonstandardized or unstructured natural language format. Advanced language models, such as large language models (LLMs), may help overcome current challenges in information exchange.
Objective
This study aims to evaluate the capability of LLMs in transforming and transferring health care data to support interoperability.
Methods
Using data from the Medical Information Mart for Intensive Care III and UK Biobank, the study conducted 3 experiments. Experiment 1 assessed the accuracy of transforming structured laboratory results into unstructured format. Experiment 2 explored the conversion of diagnostic codes between the coding frameworks of the ICD-9-CM (International Classification of Diseases, Ninth Revision, Clinical Modification), and Systematized Nomenclature of Medicine Clinical Terms (SNOMED-CT) using a traditional mapping table and a text-based approach facilitated by the LLM ChatGPT. Experiment 3 focused on extracting targeted information from unstructured records that included comprehensive clinical information (discharge notes).
Results
The text-based approach showed a high conversion accuracy in transforming laboratory results (experiment 1) and an enhanced consistency in diagnostic code conversion, particularly for frequently used diagnostic names, compared with the traditional mapping approach (experiment 2). In experiment 3, the LLM showed a positive predictive value of 87.2% in extracting generic drug names.
Conclusions
This study highlighted the potential role of LLMs in significantly improving health care data interoperability, demonstrated by their high accuracy and efficiency in data transformation and exchange. The LLMs hold vast potential for enhancing medical data exchange without complex standardization for medical terms and data structure.
ER  - 

TY  - JOUR
T1  - Re: Large language models (LLMs) in evaluation of emergency radiology reports: performance of ChatGPT-4, Perplexity and Bard
AU  - Wiwanitkit, S.
AU  - Wiwanitkit, V.
JO  - Clinical Radiology
VL  - 79
IS  - 4
SP  - e636
PY  - 2024
DA  - 2024/04/01/
SN  - 0009-9260
DO  - https://doi.org/10.1016/j.crad.2023.12.021
UR  - https://www.sciencedirect.com/science/article/pii/S000992602400014X
ER  - 

TY  - JOUR
T1  - The Impact of Multimodal Large Language Models on Health Care’s Future
AU  - Meskó, Bertalan
JO  - Journal of Medical Internet Research
VL  - 25
PY  - 2023
DA  - 2023/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/52865
UR  - https://www.sciencedirect.com/science/article/pii/S1438887123008488
KW  - artificial intelligence
KW  - ChatGPT
KW  - digital health
KW  - future
KW  - GPT-4
KW  - Generative Pre-Trained Transformer
KW  - large language models
KW  - multimodality
KW  - technology
KW  - AI
KW  - LLM
AB  - When large language models (LLMs) were introduced to the public at large in late 2022 with ChatGPT (OpenAI), the interest was unprecedented, with more than 1 billion unique users within 90 days. Until the introduction of Generative Pre-trained Transformer 4 (GPT-4) in March 2023, these LLMs only contained a single mode—text. As medicine is a multimodal discipline, the potential future versions of LLMs that can handle multimodality—meaning that they could interpret and generate not only text but also images, videos, sound, and even comprehensive documents—can be conceptualized as a significant evolution in the field of artificial intelligence (AI). This paper zooms in on the new potential of generative AI, a new form of AI that also includes tools such as LLMs, through the achievement of multimodal inputs of text, images, and speech on health care’s future. We present several futuristic scenarios to illustrate the potential path forward as multimodal LLMs (M-LLMs) could represent the gateway between health care professionals and using AI for medical purposes. It is important to point out, though, that despite the unprecedented potential of generative AI in the form of M-LLMs, the human touch in medicine remains irreplaceable. AI should be seen as a tool that can augment health care professionals rather than replace them. It is also important to consider the human aspects of health care—empathy, understanding, and the doctor-patient relationship—when deploying AI.
ER  - 

TY  - JOUR
T1  - Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions
AU  - Abd-alrazaq, Alaa
AU  - AlSaad, Rawan
AU  - Alhuwail, Dari
AU  - Ahmed, Arfan
AU  - Healy, Padraig Mark
AU  - Latifi, Syed
AU  - Aziz, Sarah
AU  - Damseh, Rafat
AU  - Alabed Alrazak, Sadam
AU  - Sheikh, Javaid
JO  - JMIR Medical Education
VL  - 9
PY  - 2023
DA  - 2023/01/01/
SN  - 2369-3762
DO  - https://doi.org/10.2196/48291
UR  - https://www.sciencedirect.com/science/article/pii/S2369376223000144
KW  - large language models
KW  - artificial intelligence
KW  - medical education
KW  - ChatGPT
KW  - GPT-4
KW  - generative AI
KW  - students
KW  - educators
AB  - The integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into medical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and competence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate the shift from an information-driven educational paradigm to an artificial intelligence (AI)–driven educational paradigm, we argue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers our perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and effective use of AI technologies in medical education.
ER  - 

TY  - JOUR
T1  - Comparing the Accuracy of Two Generated Large Language Models in Identifying Health-Related Rumors or Misconceptions and the Applicability in Health Science Popularization: Proof-of-Concept Study
AU  - Luo, Yuan
AU  - Miao, Yiqun
AU  - Zhao, Yuhan
AU  - Li, Jiawei
AU  - Chen, Yuling
AU  - Yue, Yuexue
AU  - Wu, Ying
JO  - JMIR Formative Research
VL  - 8
PY  - 2024
DA  - 2024/01/01/
SN  - 2561-326X
DO  - https://doi.org/10.2196/63188
UR  - https://www.sciencedirect.com/science/article/pii/S2561326X24006851
KW  - rumor
KW  - misconception
KW  - health science popularization
KW  - health education
KW  - large language model
KW  - LLM
KW  - applicability
KW  - accuracy
KW  - effectiveness
KW  - health related
KW  - education
KW  - health science
KW  - proof of concept
AB  - Background
Health-related rumors and misconceptions are spreading at an alarming rate, fueled by the rapid development of the internet and the exponential growth of social media platforms. This phenomenon has become a pressing global concern, as the dissemination of false information can have severe consequences, including widespread panic, social instability, and even public health crises.
Objective
The aim of the study is to compare the accuracy of rumor identification and the effectiveness of health science popularization between 2 generated large language models in Chinese (GPT-4 by OpenAI and Enhanced Representation through Knowledge Integration Bot [ERNIE Bot] 4.0 by Baidu).
Methods
In total, 20 health rumors and misconceptions, along with 10 health truths, were randomly inputted into GPT-4 and ERNIE Bot 4.0. We prompted them to determine whether the statements were rumors or misconceptions and provide explanations for their judgment. Further, we asked them to generate a health science popularization essay. We evaluated the outcomes in terms of accuracy, effectiveness, readability, and applicability. Accuracy was assessed by the rate of correctly identifying health-related rumors, misconceptions, and truths. Effectiveness was determined by the accuracy of the generated explanation, which was assessed collaboratively by 2 research team members with a PhD in nursing. Readability was calculated by the readability formula of Chinese health education materials. Applicability was evaluated by the Chinese Suitability Assessment of Materials.
Results
GPT-4 and ERNIE Bot 4.0 correctly identified all health rumors and misconceptions (100% accuracy rate). For truths, the accuracy rate was 70% (7/10) and 100% (10/10), respectively. Both mostly provided widely recognized viewpoints without obvious errors. The average readability score for the health essays was 2.92 (SD 0.85) for GPT-4 and 3.02 (SD 0.84) for ERNIE Bot 4.0 (P=.65). For applicability, except for the content and cultural appropriateness category, significant differences were observed in the total score and scores in other dimensions between them (P<.05).
Conclusions
ERNIE Bot 4.0 demonstrated similar accuracy to GPT-4 in identifying Chinese rumors. Both provided widely accepted views, despite some inaccuracies. These insights enhance understanding and correct misunderstandings. For health essays, educators can learn from readable language styles of GLLMs. Finally, ERNIE Bot 4.0 aligns with Chinese expression habits, making it a good choice for a better Chinese reading experience.
ER  - 

TY  - JOUR
T1  - ChatOps for microservice systems: A low-code approach using service composition and large language models
AU  - Wang, Sheng-Kai
AU  - Ma, Shang-Pin
AU  - Lai, Guan-Hong
AU  - Chao, Chen-Hao
JO  - Future Generation Computer Systems
VL  - 161
SP  - 518
EP  - 530
PY  - 2024
DA  - 2024/12/01/
SN  - 0167-739X
DO  - https://doi.org/10.1016/j.future.2024.07.029
UR  - https://www.sciencedirect.com/science/article/pii/S0167739X24003911
KW  - Microservices
KW  - DevOps
KW  - ChatOps
KW  - Service composition
KW  - Low-code
KW  - Large language model
KW  - Prompt engineering
AB  - The Microservice Architecture (MSA) plays a pivotal role in contemporary e-business, promoting service independence, autonomy, and continual evolution in line with the principles of DevOps. However, the distributed nature of the MSA introduces additional complexity, which requires familiarity with multiple DevOps (Development and Operations) tools, thereby increasing the learning curve. This paper presents a specialized ChatOps (Chat Operations) approach that allows MSA developers to compose new ChatOps capabilities in a low-code way (i.e., with minimal coding). The proposed ChatOps4Msa approach leverages established ChatOps functionalities to facilitate the real-time monitoring of service status, conduct service testing, track issues, and receive alerts using natural language or the proposed ChatOps Query Language (CQL). The use of large language models (LLMs) for functional intents also enhances the usability of the DevOps toolchain in microservices systems to streamline implementation.
ER  - 

TY  - JOUR
T1  - Performance of Retrieval-Augmented Large Language Models to Recommend Head and Neck Cancer Clinical Trials
AU  - Hung, Tony K W
AU  - Kuperman, Gilad J
AU  - Sherman, Eric J
AU  - Ho, Alan L
AU  - Weng, Chunhua
AU  - Pfister, David G
AU  - Mao, Jun J
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/60695
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124006563
KW  - large language model
KW  - LLM
KW  - ChatGPT
KW  - GPT-4
KW  - artificial intelligence
KW  - AI
KW  - clinical trials
KW  - decision support
KW  - LookUpTrials
KW  - cancer care delivery
KW  - head and neck oncology
KW  - head and neck cancer
KW  - retrieval augmented generation
ER  - 

TY  - JOUR
T1  - On the role of the UMLS in supporting diagnosis generation proposed by Large Language Models
AU  - Afshar, Majid
AU  - Gao, Yanjun
AU  - Gupta, Deepak
AU  - Croxford, Emma
AU  - Demner-Fushman, Dina
JO  - Journal of Biomedical Informatics
VL  - 157
SP  - 104707
PY  - 2024
DA  - 2024/09/01/
SN  - 1532-0464
DO  - https://doi.org/10.1016/j.jbi.2024.104707
UR  - https://www.sciencedirect.com/science/article/pii/S1532046424001254
KW  - Artificial intelligence
KW  - Knowledge representation (computer)
KW  - Natural language processing
KW  - Unified medical language system
KW  - Evaluation methodology
KW  - Differential diagnoses
AB  - Objective:
Traditional knowledge-based and machine learning diagnostic decision support systems have benefited from integrating the medical domain knowledge encoded in the Unified Medical Language System (UMLS). The emergence of Large Language Models (LLMs) to supplant traditional systems poses questions of the quality and extent of the medical knowledge in the models’ internal knowledge representations and the need for external knowledge sources. The objective of this study is three-fold: to probe the diagnosis-related medical knowledge of popular LLMs, to examine the benefit of providing the UMLS knowledge to LLMs (grounding the diagnosis predictions), and to evaluate the correlations between human judgments and the UMLS-based metrics for generations by LLMs.
Methods:
We evaluated diagnoses generated by LLMs from consumer health questions and daily care notes in the electronic health records using the ConsumerQA and Problem Summarization datasets. Probing LLMs for the UMLS knowledge was performed by prompting the LLM to complete the diagnosis-related UMLS knowledge paths. Grounding the predictions was examined in an approach that integrated the UMLS graph paths and clinical notes in prompting the LLMs. The results were compared to prompting without the UMLS paths. The final experiments examined the alignment of different evaluation metrics, UMLS-based and non-UMLS, with human expert evaluation.
Results:
In probing the UMLS knowledge, GPT-3.5 significantly outperformed Llama2 and a simple baseline yielding an F1 score of 10.9% in completing one-hop UMLS paths for a given concept. Grounding diagnosis predictions with the UMLS paths improved the results for both models on both tasks, with the highest improvement (4%) in SapBERT score. There was a weak correlation between the widely used evaluation metrics (ROUGE and SapBERT) and human judgments.
Conclusion:
We found that while popular LLMs contain some medical knowledge in their internal representations, augmentation with the UMLS knowledge provides performance gains around diagnosis generation. The UMLS needs to be tailored for the task to improve the LLMs predictions. Finding evaluation metrics that are aligned with human judgments better than the traditional ROUGE and BERT-based scores remains an open research question.
ER  - 

TY  - JOUR
T1  - Inductive reasoning in humans and large language models
AU  - Han, Simon Jerome
AU  - Ransom, Keith J.
AU  - Perfors, Andrew
AU  - Kemp, Charles
JO  - Cognitive Systems Research
VL  - 83
SP  - 101155
PY  - 2024
DA  - 2024/01/01/
SN  - 1389-0417
DO  - https://doi.org/10.1016/j.cogsys.2023.101155
UR  - https://www.sciencedirect.com/science/article/pii/S1389041723000839
KW  - Reasoning
KW  - Property induction
KW  - Category-based induction
KW  - Non-monotonicity
KW  - Neural networks
KW  - GPT-3.5
KW  - GPT-4
KW  - AI
KW  - Large language models
KW  - Representation
AB  - The impressive recent performance of large language models has led many to wonder to what extent they can serve as models of general intelligence or are similar to human cognition. We address this issue by applying GPT-3.5 and GPT-4 to a classic problem in human inductive reasoning known as property induction. Over two experiments, we elicit human judgments on a range of property induction tasks spanning multiple domains. Although GPT-3.5 struggles to capture many aspects of human behavior, GPT-4 is much more successful: for the most part, its performance qualitatively matches that of humans, and the only notable exception is its failure to capture the phenomenon of premise non-monotonicity. Our work demonstrates that property induction allows for interesting comparisons between human and machine intelligence and provides two large datasets that can serve as benchmarks for future work in this vein.
ER  - 

TY  - JOUR
T1  - An Investigation on Utilizing Large Language Model for Industrial Computer-Aided Design Automation
AU  - Deng, Haoxuan
AU  - Khan, Samir
AU  - Erkoyuncu, John Ahmet
JO  - Procedia CIRP
VL  - 128
SP  - 221
EP  - 226
PY  - 2024
DA  - 2024/01/01/
T2  - 34th CIRP Design Conference
SN  - 2212-8271
DO  - https://doi.org/10.1016/j.procir.2024.07.049
UR  - https://www.sciencedirect.com/science/article/pii/S2212827124006656
KW  - Design automation
KW  - Large language model
KW  - Compute-aided design
AB  - Text-to-image or 3D content generation has attracted attention in academia and industry because of its impressive performance in high-fidelity content generation with natural language commands. However, its widespread application in industrial computation-aided design (CAD) is not yet found. The main issue lies in the end-to-end generation through implicit probabilistic learning from datasets. This presents difficulties in precise, controllable, and transparent creations. Also, it is time-consuming and labor-intensive for designers to verify and customize the generated result to fit their demands. Furthermore, popular generative models offer limited support for early-stage engineering computations, leaving tedious and massive calculations to human engineers. To overcome these challenges, this paper proposes a method to apply large language model (LLM) to assist standard CAD design workflow on both engineering computation and precise 3D geometry generation. During the designing process, LLM can support the computation process with human guidance and generate accurate 3D shapes with the capability of sequential code representation and transformation. To verify the feasibility of the proposed method, a use case for a one-stage reduction gear system consisting of two gears will be given as a proof-of-concept demonstration. The result shows that the LLM can carry out the computation and get the result as expected with only a few lines of human guidance and feedback. Then, it can create CAD models with accurate parameters aligned to the computational results. It can cope with various requirements given by users and allow users to further modify the generation using the same CAD environment without much effort. Authors believe that this piece of work can shed light on utilizing the capability of LLMs for a certain part of task automation based on human beings’ intentions. With the rise of LLMs and relevant technologies, conventional CAD may shift to a more user-friendly AI-aided design (AIAD) diagram.
ER  - 

TY  - JOUR
T1  - Ethical and regulatory challenges of large language models in medicine
AU  - Ong, Jasmine Chiat Ling
AU  - Chang, Shelley Yin-Hsi
AU  - William, Wasswa
AU  - Butte, Atul J
AU  - Shah, Nigam H
AU  - Chew, Lita Sui Tjien
AU  - Liu, Nan
AU  - Doshi-Velez, Finale
AU  - Lu, Wei
AU  - Savulescu, Julian
AU  - Ting, Daniel Shu Wei
JO  - The Lancet Digital Health
VL  - 6
IS  - 6
SP  - e428
EP  - e432
PY  - 2024
DA  - 2024/06/01/
SN  - 2589-7500
DO  - https://doi.org/10.1016/S2589-7500(24)00061-X
UR  - https://www.sciencedirect.com/science/article/pii/S258975002400061X
AB  - Summary
With the rapid growth of interest in and use of large language models (LLMs) across various industries, we are facing some crucial and profound ethical concerns, especially in the medical field. The unique technical architecture and purported emergent abilities of LLMs differentiate them substantially from other artificial intelligence (AI) models and natural language processing techniques used, necessitating a nuanced understanding of LLM ethics. In this Viewpoint, we highlight ethical concerns stemming from the perspectives of users, developers, and regulators, notably focusing on data privacy and rights of use, data provenance, intellectual property contamination, and broad applications and plasticity of LLMs. A comprehensive framework and mitigating strategies will be imperative for the responsible integration of LLMs into medical practice, ensuring alignment with ethical principles and safeguarding against potential societal risks.
ER  - 

TY  - JOUR
T1  - Use of Large Language Models to Assess the Likelihood of Epidemics From the Content of Tweets: Infodemiology Study
AU  - Deiner, Michael S
AU  - Deiner, Natalie A
AU  - Hristidis, Vagelis
AU  - McLeod, Stephen D
AU  - Doan, Thuy
AU  - Lietman, Thomas M
AU  - Porco, Travis C
JO  - Journal of Medical Internet Research
VL  - 26
PY  - 2024
DA  - 2024/01/01/
SN  - 1438-8871
DO  - https://doi.org/10.2196/49139
UR  - https://www.sciencedirect.com/science/article/pii/S1438887124000979
KW  - conjunctivitis
KW  - microblog
KW  - social media
KW  - generative large language model
KW  - Generative Pre-trained Transformers
KW  - GPT-3.5
KW  - GPT-4
KW  - epidemic detection
KW  - Twitter
KW  - X formerly known as Twitter
KW  - infectious eye disease
AB  - Background
Previous work suggests that Google searches could be useful in identifying conjunctivitis epidemics. Content-based assessment of social media content may provide additional value in serving as early indicators of conjunctivitis and other systemic infectious diseases.
Objective
We investigated whether large language models, specifically GPT-3.5 and GPT-4 (OpenAI), can provide probabilistic assessments of whether social media posts about conjunctivitis could indicate a regional outbreak.
Methods
A total of 12,194 conjunctivitis-related tweets were obtained using a targeted Boolean search in multiple languages from India, Guam (United States), Martinique (France), the Philippines, American Samoa (United States), Fiji, Costa Rica, Haiti, and the Bahamas, covering the time frame from January 1, 2012, to March 13, 2023. By providing these tweets via prompts to GPT-3.5 and GPT-4, we obtained probabilistic assessments that were validated by 2 human raters. We then calculated Pearson correlations of these time series with tweet volume and the occurrence of known outbreaks in these 9 locations, with time series bootstrap used to compute CIs.
Results
Probabilistic assessments derived from GPT-3.5 showed correlations of 0.60 (95% CI 0.47-0.70) and 0.53 (95% CI 0.40-0.65) with the 2 human raters, with higher results for GPT-4. The weekly averages of GPT-3.5 probabilities showed substantial correlations with weekly tweet volume for 44% (4/9) of the countries, with correlations ranging from 0.10 (95% CI 0.0-0.29) to 0.53 (95% CI 0.39-0.89), with larger correlations for GPT-4. More modest correlations were found for correlation with known epidemics, with substantial correlation only in American Samoa (0.40, 95% CI 0.16-0.81).
Conclusions
These findings suggest that GPT prompting can efficiently assess the content of social media posts and indicate possible disease outbreaks to a degree of accuracy comparable to that of humans. Furthermore, we found that automated content analysis of tweets is related to tweet volume for conjunctivitis-related posts in some locations and to the occurrence of actual epidemics. Future work may improve the sensitivity and specificity of these methods for disease outbreak detection.
ER  - 

TY  - JOUR
T1  - Context-biased vs. structure-biased disambiguation of relative clauses in large language models
AU  - Issa, Elsayed
AU  - Atouf, Noureddine
JO  - Procedia Computer Science
VL  - 244
SP  - 425
EP  - 431
PY  - 2024
DA  - 2024/01/01/
T2  - 6th International Conference on AI in Computational Linguistics
SN  - 1877-0509
DO  - https://doi.org/10.1016/j.procs.2024.10.217
UR  - https://www.sciencedirect.com/science/article/pii/S1877050924030187
KW  - LLMs
KW  - psycholinguistics
KW  - attachment preferences
KW  - relative clause
KW  - ambiguity
AB  - This work investigates the processing behavior of large language models (LLMs) in sentences involving ambiguous relative clauses (RCs). We are particularly interested in unravelling attachment preferences of LLMs in disambiguating RCs (complementizer phrases CPs modifying a genitival phrase), which are either semantically (context-biased) or syntactically (structure-biased) associated to one of the preceding NP referents. A low interpretation of the RC occurs when it is joined to the local NP (low attachment). A high interpretation is provided when the RC modifies the distant NP (high attachment). We create a small dataset of parallel low- and high-attachment sentences. We use zero-shot prompting to evaluate a set of LLMs based on insights from psycholinguistic experiments. Our results show variability in the performance of some models that favor low attachment (semantically-related meanings in the CP) while other models can resolve ambiguity by choosing high-attachment (structure-biased CPs). The findings are discussed in light of directing future experimental studies to consider a comparative paradigm encompassing both multi-modal LLMs and human subjects.
ER  - 

TY  - JOUR
T1  - Empowering digital twins with large language models for global temporal feature learning
AU  - Sun, Yicheng
AU  - Zhang, Qi
AU  - Bao, Jinsong
AU  - Lu, Yuqian
AU  - Liu, Shimin
JO  - Journal of Manufacturing Systems
VL  - 74
SP  - 83
EP  - 99
PY  - 2024
DA  - 2024/06/01/
SN  - 0278-6125
DO  - https://doi.org/10.1016/j.jmsy.2024.02.015
UR  - https://www.sciencedirect.com/science/article/pii/S0278612524000372
KW  - Large Language Model (LLM)
KW  - Digital Twin
KW  - Multi-Agent Systems (MAS)
AB  - Digital Twin (DT), as an efficient technology for virtual-physical interaction, has demonstrated significant application potential in various industries. Intelligent agent-driven digital twin systems excel in analysis, decision-making, and control, making them highly suitable for manufacturing resource scheduling, diagnostic decision-making, and other requirements. However, current intelligent agents have notable deficiencies in adaptability, data utilization, and interpretability. This limitation undermines decision security and acceptability, creating barriers for user intervention. Therefore, this paper introduces a DT multi agent architecture driven by Large Language Models (LLMs). Agents perceive the characteristics of physical systems, particularly their temporal characteristics, by integrating data from various modalities. Multiple agents achieve insights through specific interaction mechanisms, while maintaining traceability. To showcase the advantages and characteristics of this architecture, we developed a typical application scenario for equipment maintenance. The effectiveness of each framework component was validated through ablation experiments. The experimental results suggest that the proposed framework holds promising and extensive application prospects.
ER  - 

TY  - JOUR
T1  - Large language model-based code generation for the control of construction assembly robots: A hierarchical generation approach
AU  - Luo, Hanbin
AU  - Wu, Jianxin
AU  - Liu, Jiajing
AU  - Antwi-Afari, Maxwell Fordjour
JO  - Developments in the Built Environment
VL  - 19
SP  - 100488
PY  - 2024
DA  - 2024/10/01/
SN  - 2666-1659
DO  - https://doi.org/10.1016/j.dibe.2024.100488
UR  - https://www.sciencedirect.com/science/article/pii/S2666165924001698
KW  - Construction assembly robot
KW  - Large language model
KW  - Code generation
KW  - 
KW  - Human–robot collaboration
AB  - Offline programming (OLP) is a mainstream approach for controlling assembly robots at construction sites. However, existing methods are tailored to specific assembly tasks and workflows, and thus lack flexibility. Additionally, the emerging large language model (LLM)-based OLP cannot effectively handle the code logic of robot programming. Thus, this paper addresses the question: How can robot control programs be generated effectively and accurately for diverse construction assembly tasks using LLM techniques? This paper describes a closed user-on-the-loop control framework for construction assembly robots based on LLM techniques. A hierarchical strategy to generate robot control programs is proposed to logically integrate code generation at high and low levels. Additionally, customized application programming interfaces and a chain of action are combined to enhance the LLM's understanding of assembly action logic. An assembly task set was designed to evaluate the feasibility and reliability of the proposed approach. The results show that the proposed approach (1) is widely applicable to diverse assembly tasks, and (2) can improve the quality of the generated code by decreasing the number of errors. Our approach facilitates the automation of construction assembly tasks by simplifying the robot control process.
ER  - 

TY  - JOUR
T1  - Evaluating emotional and subjective responses in synthetic art-related dialogues: A multi-stage framework with large language models
AU  - Luna-Jiménez, Cristina
AU  - Gil-Martín, Manuel
AU  - D’Haro, Luis Fernando
AU  - Fernández-Martínez, Fernando
AU  - San-Segundo, Rubén
JO  - Expert Systems with Applications
VL  - 255
SP  - 124524
PY  - 2024
DA  - 2024/12/01/
SN  - 0957-4174
DO  - https://doi.org/10.1016/j.eswa.2024.124524
UR  - https://www.sciencedirect.com/science/article/pii/S0957417424013915
KW  - Data and text mining
KW  - Dialogues generation
KW  - Dialogues evaluation
KW  - Affective-computing
AB  - The appearance of Large Language Models (LLM) has implied a qualitative step forward in the performance of conversational agents, and even in the generation of creative texts. However, previous applications of these models in generating dialogues neglected the impact of ‘hallucinations’ in the context of generating synthetic dialogues, thus omitting this central aspect in their evaluations. For this reason, we propose an open-source and flexible framework called GenEvalGPT framework: a comprehensive multi-stage evaluation strategy utilizing diverse metrics. The objective is two-fold: first, the goal is to assess the extent to which synthetic dialogues between a chatbot and a human align with the specified commands, determining the successful creation of these dialogues based on the provided specifications; and second, to evaluate various aspects of emotional and subjective responses. Assuming that dialogues to be evaluated were synthetically produced from specific profiles, the first evaluation stage utilizes LLMs to reconstruct the original templates employed in dialogue creation. The success of this reconstruction is then assessed in a second stage using lexical and semantic objective metrics. On the other hand, crafting a chatbot’s behaviors demands careful consideration to encompass a diverse range of interactions it is meant to engage in. Synthetic dialogues play a pivotal role in this context, as they can be deliberately synthesized to emulate various behaviors. This is precisely the objective of the third stage: evaluating whether the generated dialogues adhere to the required aspects concerning emotional and subjective responses. To validate the capabilities of the proposed framework, we applied it to recognize whether the chatbot exhibited one of two distinct behaviors in the synthetically generated dialogues: being emotional and providing subjective responses, or remaining neutral. This evaluation will encompass traditional metrics and automatic metrics generated by the LLM. In our use case of art-related dialogues, our findings reveal that the capacity to recover templates or profiles is more effective for information or profile items that are objective and factual, in contrast to those related to mental states or subjective facts. For the emotional and subjective behavior assessment, rule-based metrics achieved a 79% of accuracy in detecting emotions or subjectivity (anthropic), and an 82% on the LLM automatic metrics. The combination of these metrics and stages could help to decide which of the generated dialogues should be maintained depending on the applied policy, which could vary from preserving between 57% to 93% of the initial dialogues.
ER  - 

TY  - JOUR
T1  - Extracting structured data from organic synthesis procedures using a fine-tuned large language model††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d4dd00091a
AU  - Ai, Qianxiang
AU  - Meng, Fanwang
AU  - Shi, Jiale
AU  - Pelkie, Brenden
AU  - Coley, Connor W.
JO  - Digital Discovery
VL  - 3
IS  - 9
SP  - 1822
EP  - 1831
PY  - 2024
DA  - 2024/09/11/
SN  - 2635-098X
DO  - https://doi.org/10.1039/d4dd00091a
UR  - https://www.sciencedirect.com/science/article/pii/S2635098X2400144X
AB  - The popularity of data-driven approaches and machine learning (ML) techniques in the field of organic chemistry and its various subfields has increased the value of structured reaction data. Most data in chemistry is represented by unstructured text, and despite the vastness of the organic chemistry literature (papers, patents), manual conversion from unstructured text to structured data remains a largely manual endeavor. Software tools for this task would facilitate downstream applications such as reaction prediction and condition recommendation. In this study, we fine-tune a large language model (LLM) to extract reaction information from organic synthesis procedure text into structured data following the Open Reaction Database (ORD) schema, a comprehensive data structure designed for organic reactions. The fine-tuned model produces syntactically correct ORD records with an average accuracy of 91.25% for ORD “messages” (e.g., full compound, workups, or condition definitions) and 92.25% for individual data fields (e.g., compound identifiers, mass quantities), with the ability to recognize compound-referencing tokens and to infer reaction roles. We investigate its failure modes and evaluate performance on specific subtasks such as reaction role classification.
ER  - 

TY  - JOUR
T1  - Comprehensiveness of Large Language Models in Patient Queries on Gingival and Endodontic Health
AU  - Zhang, Qian
AU  - Wu, Zhengyu
AU  - Song, Jinlin
AU  - Luo, Shuicai
AU  - Chai, Zhaowu
JO  - International Dental Journal
VL  - 75
IS  - 1
SP  - 151
EP  - 157
PY  - 2025
DA  - 2025/02/01/
SN  - 0020-6539
DO  - https://doi.org/10.1016/j.identj.2024.06.022
UR  - https://www.sciencedirect.com/science/article/pii/S0020653924001953
KW  - Artificial intelligence
KW  - Large language models
KW  - Oral healthcare
KW  - Gingival and endodontic health
AB  - Aim
Given the increasing interest in using large language models (LLMs) for self-diagnosis, this study aimed to evaluate the comprehensiveness of two prominent LLMs, ChatGPT-3.5 and ChatGPT-4, in addressing common queries related to gingival and endodontic health across different language contexts and query types.
Methods
We assembled a set of 33 common real-life questions related to gingival and endodontic healthcare, including 17 common-sense questions and 16 expert questions. Each question was presented to the LLMs in both English and Chinese. Three specialists were invited to evaluate the comprehensiveness of the responses on a five-point Likert scale, where a higher score indicated greater quality responses.
Results
LLMs performed significantly better in English, with an average score of 4.53, compared to 3.95 in Chinese (Mann–Whitney U test, P < .05). Responses to common sense questions received higher scores than those to expert questions, with averages of 4.46 and 4.02 (Mann–Whitney U test, P < .05). Among the LLMs, ChatGPT-4 consistently outperformed ChatGPT-3.5, achieving average scores of 4.45 and 4.03 (Mann–Whitney U test, P < .05).
Conclusions
ChatGPT-4 provides more comprehensive responses than ChatGPT-3.5 for queries related to gingival and endodontic health. Both LLMs perform better in English and on common sense questions. However, the performance discrepancies across different language contexts and the presence of inaccurate responses suggest that further evaluation and understanding of their limitations are crucial to avoid potential misunderstandings.
Clinical Relevance
This study revealed the performance differences of ChatGPT-3.5 and ChatGPT-4 in handling gingival and endodontic health issues across different language contexts, providing insights into the comprehensiveness and limitations of LLMs in addressing common oral healthcare queries.
ER  - 

TY  - JOUR
T1  - Large Language Models for Mental Health Applications: Systematic Review
AU  - Guo, Zhijun
AU  - Lai, Alvina
AU  - Thygesen, Johan H
AU  - Farrington, Joseph
AU  - Keen, Thomas
AU  - Li, Kezhi
JO  - JMIR Mental Health
VL  - 11
PY  - 2024
DA  - 2024/01/01/
SN  - 2368-7959
DO  - https://doi.org/10.2196/57400
UR  - https://www.sciencedirect.com/science/article/pii/S2368795924001173
KW  - large language models
KW  - mental health
KW  - digital health care
KW  - ChatGPT
KW  - Bidirectional Encoder Representations from Transformers
KW  - BERT
AB  - Background
Large language models (LLMs) are advanced artificial neural networks trained on extensive datasets to accurately understand and generate natural language. While they have received much attention and demonstrated potential in digital health, their application in mental health, particularly in clinical settings, has generated considerable debate.
Objective
This systematic review aims to critically assess the use of LLMs in mental health, specifically focusing on their applicability and efficacy in early screening, digital interventions, and clinical settings. By systematically collating and assessing the evidence from current studies, our work analyzes models, methodologies, data sources, and outcomes, thereby highlighting the potential of LLMs in mental health, the challenges they present, and the prospects for their clinical use.
Methods
Adhering to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, this review searched 5 open-access databases: MEDLINE (accessed by PubMed), IEEE Xplore, Scopus, JMIR, and ACM Digital Library. Keywords used were (mental health OR mental illness OR mental disorder OR psychiatry) AND (large language models). This study included articles published between January 1, 2017, and April 30, 2024, and excluded articles published in languages other than English.
Results
In total, 40 articles were evaluated, including 15 (38%) articles on mental health conditions and suicidal ideation detection through text analysis, 7 (18%) on the use of LLMs as mental health conversational agents, and 18 (45%) on other applications and evaluations of LLMs in mental health. LLMs show good effectiveness in detecting mental health issues and providing accessible, destigmatized eHealth services. However, assessments also indicate that the current risks associated with clinical use might surpass their benefits. These risks include inconsistencies in generated text; the production of hallucinations; and the absence of a comprehensive, benchmarked ethical framework.
Conclusions
This systematic review examines the clinical applications of LLMs in mental health, highlighting their potential and inherent risks. The study identifies several issues: the lack of multilingual datasets annotated by experts, concerns regarding the accuracy and reliability of generated content, challenges in interpretability due to the “black box” nature of LLMs, and ongoing ethical dilemmas. These ethical concerns include the absence of a clear, benchmarked ethical framework; data privacy issues; and the potential for overreliance on LLMs by both physicians and patients, which could compromise traditional medical practices. As a result, LLMs should not be considered substitutes for professional mental health services. However, the rapid development of LLMs underscores their potential as valuable clinical aids, emphasizing the need for continued research and development in this area.
Trial Registration
PROSPERO CRD42024508617; https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=508617
ER  - 

TY  - JOUR
T1  - Data science opportunities of large language models for neuroscience and biomedicine
AU  - Bzdok, Danilo
AU  - Thieme, Andrew
AU  - Levkovskyy, Oleksiy
AU  - Wren, Paul
AU  - Ray, Thomas
AU  - Reddy, Siva
JO  - Neuron
VL  - 112
IS  - 5
SP  - 698
EP  - 717
PY  - 2024
DA  - 2024/03/06/
SN  - 0896-6273
DO  - https://doi.org/10.1016/j.neuron.2024.01.016
UR  - https://www.sciencedirect.com/science/article/pii/S0896627324000424
AB  - Large language models (LLMs) are a new asset class in the machine-learning landscape. Here we offer a primer on defining properties of these modeling techniques. We then reflect on new modes of investigation in which LLMs can be used to reframe classic neuroscience questions to deliver fresh answers. We reason that LLMs have the potential to (1) enrich neuroscience datasets by adding valuable meta-information, such as advanced text sentiment, (2) summarize vast information sources to overcome divides between siloed neuroscience communities, (3) enable previously unthinkable fusion of disparate information sources relevant to the brain, (4) help deconvolve which cognitive concepts most usefully grasp phenomena in the brain, and much more.
ER  - 

TY  - JOUR
T1  - Large Language Model for Assisted Robot Programming in Micro-Assembly
AU  - Wiemann, Rolf
AU  - Terei, Niklas
AU  - Raatz, Annika
JO  - Procedia CIRP
VL  - 130
SP  - 244
EP  - 249
PY  - 2024
DA  - 2024/01/01/
T2  - 57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)
SN  - 2212-8271
DO  - https://doi.org/10.1016/j.procir.2024.10.083
UR  - https://www.sciencedirect.com/science/article/pii/S221282712401240X
KW  - Large Language Models
KW  - Intuitive Robot Programming
KW  - Micro-Assembly
KW  - ROS2
AB  - In the context of the rapid development of micro-devices and photonics, the importance of efficient automation solutions is becoming increasingly important. The automation of assembly processes in particular is a decisive factor, as assembly is responsible for a large proportion of costs. The programming of robots, particularly in the field of micro-assembly, requires extensive specialist knowledge due to the complexity of the assembly systems and processes. Increasingly more powerful large language models (LLMs) enable their use in robot programming. These allow interaction through natural language, providing an intuitive user interface. In this work, we utilize a LLM to assist users in programming new micro-assembly processes. We develop an assistant that we integrate into a Robot Operating System 2 (ROS2) framework. This framework enables the control and programming of a micro-assembly robot via ROS2 services. The assistant has access to these services and information about the components. Based on user requests, the assistant can parameterize these services and arrange them sequentially according to the assembly task. The assembly sequence can subsequently be modified by the user, either by using the assistant again or manually. We test the performance of the developed assistant using example tasks and demonstrate that, particularly, shorter sequences can be reliably generated. Finally, we present potential improvements and extensions of the application.
ER  - 

TY  - JOUR
T1  - Automatic bridge inspection database construction through hybrid information extraction and large language models
AU  - Zhang, Chenhong
AU  - Lei, Xiaoming
AU  - Xia, Ye
AU  - Sun, Limin
JO  - Developments in the Built Environment
VL  - 20
SP  - 100549
PY  - 2024
DA  - 2024/12/01/
SN  - 2666-1659
DO  - https://doi.org/10.1016/j.dibe.2024.100549
UR  - https://www.sciencedirect.com/science/article/pii/S2666165924002308
KW  - Bridge inspection data
KW  - Natural language processing
KW  - Information extraction
KW  - Large languge model
KW  - Pseudo label
AB  - Regular bridge inspections generate extensive reports that, while critical for maintenance, often remain underutilized due to their unstructured format. Traditional information extraction methods depend on intricate labeling systems that commonly require time-consuming and labor-intensive labeling. This paper presents a novel bridge inspection database construction method leveraging LLM-assisted information extraction. First, we introduce the pseudo-labelling method using a closed-source LLM to generate high-quality data. Then we propose the hybrid extraction pipeline to extract relevant information segments and process them by a generation-based IE model, fine-tuned on pseudo-labeled data. Finally, the extracted data is used to construct the bridge inspection database. The proposed method, validated with real-world data, not only demonstrates higher extraction precision than the closed-source LLM used for pseudo-labeling but also outperforms traditional methods in both data preparation time and extraction accuracy. This approach provides a scalable solution for more proactive and data-driven bridge maintenance strategies.
ER  - 

TY  - JOUR
T1  - ChatGPT, Llama, can you write my report? An experiment on assisted digital forensics reports written using (local) large language models
AU  - Michelet, Gaëtan
AU  - Breitinger, Frank
JO  - Forensic Science International: Digital Investigation
VL  - 48
SP  - 301683
PY  - 2024
DA  - 2024/03/01/
T2  - DFRWS EU 2024 - Selected Papers from the 11th Annual Digital Forensics Research Conference Europe
SN  - 2666-2817
DO  - https://doi.org/10.1016/j.fsidi.2023.301683
UR  - https://www.sciencedirect.com/science/article/pii/S2666281723002020
KW  - Digital forensics investigation
KW  - Local large language models
KW  - ChatGPT
KW  - Report automation
KW  - Assisted report writing
AB  - Generative AIs, especially Large Language Models (LLMs) such as ChatGPT or Llama, have advanced significantly, positioning them as valuable tools for digital forensics. While initial studies have explored the potential of ChatGPT in the context of investigations, the question of to what extent LLMs can assist the forensic report writing process remains unresolved. To answer the question, this article first examines forensic reports with the goal of generalization (e.g., finding the ‘average structure’ of a report). We then evaluate the strengths and limitations of LLMs for generating the different parts of the forensic report using a case study. This work thus provides valuable insights into the automation of report writing, a critical facet of digital forensics investigations. We conclude that combined with thorough proofreading and corrections, LLMs may assist practitioners during the report writing process but at this point cannot replace them.
ER  - 
